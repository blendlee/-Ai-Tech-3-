{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uOnz8OxdbN3y"
   },
   "source": [
    "# Natural Language Processing\n",
    "\n",
    "## ê¸°ë³¸ê³¼ì œ 3: Subword-level Language Model\n",
    "\n",
    "> Reference ì½”ë“œëŠ” Solution ê³¼ í•¨ê»˜ ê³µê°œë©ë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NSNON1TAbj2i"
   },
   "source": [
    "### Introduction\n",
    "\n",
    "\n",
    "* ë³¸ ê³¼ì œì˜ ëª©ì ì€ ì„œë¸Œì›Œë“œ í† í°í™” (Subword Tokenization)ì˜ í•„ìš”ì„±ì„ ì§ì ‘ ëŠë¼ê³  ì„œë¸Œì›Œë“œ í† í°í™” ì•Œê³ ë¦¬ì¦˜ ì¤‘ í•˜ë‚˜ì¸ Byte Pair Encodingì„ êµ¬í˜„í•´ë´…ë‹ˆë‹¤.\n",
    "* ì„œë¸Œì›ŒíŠ¸ í† í°í™” ê¸°ë°˜ language modelì„ êµ¬í˜„í•˜ë©´ì„œ ì´ì „ ê³¼ì œì˜ Word-level language modelê³¼ ë¹„êµí•´ë³´ëŠ” ì‹œê°„ì„ ê°–ê² ìŠµë‹ˆë‹¤. ì¶”ê°€ì ìœ¼ë¡œ RNNì„ LSTMìœ¼ë¡œ ë³€ê²½í–ˆì„ ë•Œì˜ ì„±ëŠ¥ ì°¨ì´ì— ëŒ€í•´ ì‚´í´ë³´ê² ìŠµë‹ˆë‹¤.\n",
    "* Subword-level language modelì„ êµ¬í˜„í•˜ê³ , ì£¼ì–´ì§„ ë°ì´í„°ë¥¼ ê°€ê³µí•˜ì—¬ ëª¨ë¸ì„ í•™ìŠµí•œ í›„ í•™ìŠµëœ ì–¸ì–´ ëª¨ë¸ì„ ì´ìš©í•´ ë¬¸ì¥ì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "* **ANSWER HERE** ì´ë¼ê³  ì‘ì„±ëœ ë¶€ë¶„ì„ ì±„ì›Œ ì™„ì„±í•˜ì‹œë©´ ë©ë‹ˆë‹¤. ë‹¤ë¥¸ ë¶€ë¶„ì˜ ì½”ë“œë¥¼ ë³€ê²½í•˜ë©´ ì˜¤ë¥˜ê°€ ë°œìƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "> ê³¼ì œ ì™„ì„± í›„ ipynb íŒŒì¼ì„ ì œì¶œí•´ ì£¼ì„¸ìš”.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "70_V429wBxti"
   },
   "source": [
    "### 0. ë°ì´í„° ì—…ë¡œë“œ\n",
    "\n",
    "\n",
    "1. Boostcourse [ê¸°ë³¸ ê³¼ì œ] Subword-level Language Model ì—ì„œ `wikitext-2.zip` íŒŒì¼ì„ ë‹¤ìš´ë°›ìŠµë‹ˆë‹¤.\n",
    "2. ë³¸ Colab í™˜ê²½ì— `train.txt`, `dev.txt`, `test.txt` íŒŒì¼ì„ ì—…ë¡œë“œí•©ë‹ˆë‹¤.\n",
    "3. `! ls` command ë¥¼ ì‹¤í–‰í–ˆì„ ë•Œ, `sample_data  test.txt  train.txt  valid.txt` ê°€ ë‚˜ì˜¤ë©´ ì„±ê³µì ìœ¼ë¡œ ë°ì´í„° ì¤€ë¹„ê°€ ì™„ë£Œëœ ê²ƒ ì…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ufq1RSMJo41s",
    "outputId": "4fd66dda-88b6-4554-9e6c-a910f184ca50"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "'[Basic_2]_RNN_based_Language_Model ê³¼ì œ.ipynb'\t\t      practice.ipynb\n",
      "'[Basic_3]_Subword_level_Language_Model_ipynbì˜_ì‚¬ë³¸.ipynb'   test.txt\n",
      " generate.txt\t\t\t\t\t\t      train.txt\n",
      " model.pt\t\t\t\t\t\t      valid.txt\n"
     ]
    }
   ],
   "source": [
    "! ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AFwHrOCK6UaE",
    "outputId": "24af4031-5121-43f2-8078-fa20838d1bce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36718\n",
      " \n",
      "\n",
      " = Valkyria Chronicles III = \n",
      "\n",
      " \n",
      "\n",
      " SenjÅ no Valkyria 3 : <unk> Chronicles ( Japanese : æˆ¦å ´ã®ãƒ´ã‚¡ãƒ«ã‚­ãƒ¥ãƒªã‚¢3 , lit . Valkyria of the Battlefield 3 ) , commonly referred to as Valkyria Chronicles III outside Japan , is a tactical role @-@ playing video game developed by Sega and Media.Vision for the PlayStation Portable . Released in January 2011 in Japan , it is the third game in the Valkyria series . <unk> the same fusion of tactical and real @-@ time gameplay as its predecessors , the story runs parallel to the first game and follows the \" Nameless \" , a penal military unit serving the nation of Gallia during the Second Europan War who perform secret black operations and are pitted against the Imperial unit \" <unk> Raven \" . \n",
      "\n",
      " The game began development in 2010 , carrying over a large portion of the work done on Valkyria Chronicles II . While it retained the standard features of the series , it also underwent multiple adjustments , such as making the game more <unk> for series newcomers . Character designer <unk> Honjou and composer Hitoshi Sakimoto both returned from previous entries , along with Valkyria Chronicles II director Takeshi Ozawa . A large team of writers handled the script . The game 's opening theme was sung by May 'n . \n",
      "\n",
      " It met with positive sales in Japan , and was praised by both Japanese and western critics . After release , it received downloadable content , along with an expanded edition in November of that year . It was also adapted into manga and an original video animation series . Due to low sales of Valkyria Chronicles II , Valkyria Chronicles III was not localized , but a fan translation compatible with the game 's expanded edition was released in 2014 . Media.Vision would return to the franchise with the development of Valkyria : Azure Revolution for the PlayStation 4 . \n",
      "\n",
      " \n",
      "\n",
      " = = Gameplay = = \n",
      "\n",
      " \n",
      "\n",
      " As with previous <unk> Chronicles games , Valkyria Chronicles III is a tactical role @-@ playing game where players take control of a military unit and take part in missions against enemy forces . Stories are told through comic book @-@ like panels with animated character portraits , with characters speaking partially through voiced speech bubbles and partially through <unk> text . The player progresses through a series of linear missions , gradually unlocked as maps that can be freely <unk> through and replayed as they are unlocked . The route to each story location on the map varies depending on an individual player 's approach : when one option is selected , the other is sealed off to the player . Outside missions , the player characters rest in a camp , where units can be customized and character growth occurs . Alongside the main story missions are character @-@ specific sub missions relating to different squad members . After the game 's completion , additional episodes are unlocked , some of them having a higher difficulty than those found in the rest of the game . There are also love simulation elements related to the game 's two main <unk> , although they take a very minor role . \n",
      "\n"
     ]
    }
   ],
   "source": [
    "path_train = '/opt/ml/RNN_homework/train.txt'\n",
    "with open(path_train, 'r', encoding=\"utf8\") as f:\n",
    "    corpus_train = f.readlines()    \n",
    "\n",
    "# train dataset í¬ê¸° í™•ì¸\n",
    "print(len(corpus_train))\n",
    "\n",
    "# ì²˜ìŒ 10 ë¬¸ì¥ì„ print í•´ ë´…ì‹œë‹¤.\n",
    "for sent in corpus_train[:10]:\n",
    "    print(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_xzSMF9RJyzg"
   },
   "source": [
    "### 1. ì„œë¸Œì›Œë“œ í† í°í™”ì˜ í•„ìš”ì„±\n",
    "\n",
    "ğŸ’¡ ì„œë¸Œì›Œë“œ(Subword)ëŠ” ë¬´ì—‡ì¸ê°€ìš”?\n",
    "\n",
    "ì„œë¸Œì›Œë“œëŠ” í•˜ë‚˜ì˜ ë‹¨ì–´ë¥¼ ì—¬ëŸ¬ê°œì˜ ë‹¨ìœ„ë¡œ ë¶„ë¦¬í–ˆì„ ë•Œ í•˜ë‚˜ì˜ ë‹¨ìœ„ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. `subword`ë¥¼ ì„œë¸Œì›Œë“œ ë‹¨ìœ„ë¡œ ë‚˜íƒ€ë‚¸ í•˜ë‚˜ì˜ ì˜ˆì‹œëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.\n",
    "\n",
    " * `sub` + `word`\n",
    "\n",
    "`sub`ë¼ëŠ” ì ‘ë‘ì‚¬ì™€ `word`ë¼ê³  í•˜ëŠ” ì–´ê·¼ìœ¼ë¡œ ë‚˜ëˆ„ì–´ `subword`ë¼ê³  í•˜ëŠ” ë‹¨ì–´ë¥¼ 2ê°œì˜ ì„œë¸Œ ì›Œë“œë¡œ ë‚˜íƒ€ëƒˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "ì´ì™¸ì—ë„ ë‹¤ì–‘í•œ í˜•íƒœì˜ ì„œë¸Œì›Œë“œë¡œ ë‚˜íƒ€ë‚¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. (e.g., `su` + `bword`, `s` + `ubword`, `subwor` + `d`)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BVQgjQJdAbWh"
   },
   "source": [
    "ğŸ’¡ ê·¸ëŸ¼ ì„œë¸Œì›Œë“œ í† í°í™”(Subword tokenization)ëŠ” ë¬´ì—‡ì¸ê°€ìš”?\n",
    "\n",
    "ì„œë¸Œì›Œë“œ í† í°í™”ëŠ” ë§ ê·¸ëŒ€ë¡œ ì„œë¸Œì›Œë“œ ë‹¨ìœ„ë¡œ í† í°í™”ë¥¼ í•œë‹¤ëŠ” ëœ»ì…ë‹ˆë‹¤.\n",
    "ê¸°ë³¸ ê³¼ì œ 1ì—ì„œ ë‚˜ì˜¨ ë‹¨ì–´ë‹¨ìœ„ í† í°í™”ë¥¼ ì ìš©í•œ ë’¤, ì„œë¸Œì›Œë“œ í† í°í™”ë¥¼ ìˆ˜í–‰í•œ ì˜ˆì‹œë¥¼ ë³´ê² ìŠµë‹ˆë‹¤.\n",
    "\n",
    "ì„œë¸Œì›Œë“œ í† í°í™”ë¥¼ ì ìš©í–ˆì„ ë•ŒëŠ” ë‹¤ìŒê³¼ ê°™ì´ í† í°í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "* Example 1\n",
    "> \"I have a meal\" -> ['I', 'hav', 'e', 'a', 'me', 'al']\n",
    ">\n",
    "> \"ë‚˜ëŠ” ë°¥ì„ ë¨¹ëŠ”ë‹¤\" -> ['ë‚˜', 'ëŠ”', 'ë°¥', 'ì„', 'ë¨¹ëŠ”', 'ë‹¤']\n",
    "\n",
    "ë‹¨ì–´ë‹¨ìœ„ê°€ ì•„ë‹ˆë¼ ê·¸ë³´ë‹¤ ë” ì˜ê²Œ ìª¼ê°  ì„œë¸Œì›Œë“œ ë‹¨ìœ„ë¡œ ë¬¸ì¥ì„ í† í°í™”í•©ë‹ˆë‹¤.\n",
    "\n",
    "ìœ„ì—ì„œ ë§ì”€ë“œë¦° ê²ƒê³¼ ê°™ì´ ì—¬ëŸ¬ê°€ì§€ ê²½ìš°ì˜ ìˆ˜ê°€ ê°€ëŠ¥í•©ë‹ˆë‹¤.\n",
    "\n",
    "* Example 2\n",
    "> \"I have a meal\" -> ['I', 'ha', 've', 'a', 'mea', 'l']\n",
    ">\n",
    "> \"ë‚˜ëŠ” ë°¥ì„ ë¨¹ëŠ”ë‹¤\" -> ['ë‚˜', 'ëŠ”', 'ë°¥', 'ì„', 'ë¨¹', 'ëŠ”ë‹¤']\n",
    "\n",
    "ê·¸ë ‡ì§€ë§Œ ê¸°ë³¸ì ìœ¼ë¡œ ê³µë°±ì„ ë„˜ì–´ì„  ì„œë¸Œë¥¼ êµ¬ì„±í•˜ì§„ ì•ŠìŠµë‹ˆë‹¤.\n",
    "ì˜ˆë¥¼ ë“¤ì–´ ë‹¤ìŒê³¼ ê°™ì´ í† í°í™”ë¥¼ ìˆ˜í–‰í•˜ì§„ ì•ŠìŠµë‹ˆë‹¤.\n",
    "\n",
    "* Example 3\n",
    "> \"I have a meal\" -> ['Iha', 've', 'am', 'ea', 'l']\n",
    ">\n",
    "> \"ë‚˜ëŠ” ë°¥ì„ ë¨¹ëŠ”ë‹¤\" -> ['ë‚˜ëŠ”ë°¥', 'ì„ë¨¹', 'ëŠ”ë‹¤']\n",
    "\n",
    "(ì°¸ê³ 4: [Huggingface: subword-tokenization](https://huggingface.co/transformers/tokenizer_summary.html#subword-tokenization))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SPRNaFhMEK67"
   },
   "source": [
    "ğŸ’¡ Subword tokenizationì€ ì™œ í•„ìš”í•œê°€ìš”?\n",
    "\n",
    "ì²« ë²ˆì§¸ ì´ìœ ëŠ” ì´ ì„¸ìƒì— ë‹¨ì–´ê°€ ë„ˆë¬´ ë§ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.\n",
    "ì´ì „ ê³¼ì œì—ì„œ ì‚¬ìš©í–ˆë˜ ì½”ë“œë¥¼ ë¶ˆëŸ¬ì™€ ê·¸ í•„ìš”ì„±ì„ ìƒê°í•´ ë´…ì‹œë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "id": "SWd09aUBGWa9"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "class Dictionary(object):\n",
    "    def __init__(self):\n",
    "        self.token2id = {}\n",
    "        self.id2token = []\n",
    "\n",
    "    def add_word(self, word):\n",
    "        if word not in self.token2id:\n",
    "            self.id2token.append(word)\n",
    "            self.token2id[word] = len(self.id2token) - 1\n",
    "        return self.token2id[word]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.id2token)\n",
    "\n",
    "class Corpus(object):\n",
    "    def __init__(self, path):\n",
    "        self.dictionary = Dictionary()\n",
    "        self.train = self.tokenize(os.path.join(path, 'train.txt'))\n",
    "        self.valid = self.tokenize(os.path.join(path, 'valid.txt'))\n",
    "        self.test = self.tokenize(os.path.join(path, 'test.txt'))\n",
    "\n",
    "    def tokenize(self, path):\n",
    "        \"\"\"Tokenizes a text file.\"\"\"\n",
    "        assert os.path.exists(path)\n",
    "        # Add words to the dictionary\n",
    "        with open(path, 'r', encoding=\"utf-8\") as f:\n",
    "            for line in f:\n",
    "                words = line.split() + ['<eos>']\n",
    "                for word in words:\n",
    "                    self.dictionary.add_word(word)\n",
    "\n",
    "        # Tokenize file content\n",
    "        with open(path, 'r', encoding=\"utf-8\") as f:\n",
    "            idss = []\n",
    "            for line in f:\n",
    "                words = line.split() + ['<eos>']\n",
    "                ids = []\n",
    "                for word in words:\n",
    "                    ids.append(self.dictionary.token2id[word])\n",
    "                idss.append(torch.tensor(ids).type(torch.int64))\n",
    "            ids = torch.cat(idss)\n",
    "\n",
    "        return ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "id": "FLT1GR2To41u"
   },
   "outputs": [],
   "source": [
    "from typing import Union, Tuple\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, \n",
    "        rnn_type: str,\n",
    "        vocab_size: int,\n",
    "        embedding_size: int=200,\n",
    "        hidden_size: int=200,\n",
    "        num_hidden_layers: int=2,\n",
    "        dropout: float=0.5\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.rnn_type = rnn_type\n",
    "        self.vocab_size = vocab_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_hidden_layer = num_hidden_layers\n",
    "        assert rnn_type in {'LSTM', 'GRU', 'RNN_TANH', 'RNN_RELU'}\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_size)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        if rnn_type.startswith('RNN'):\n",
    "            nonlinearity = rnn_type.split('_')[-1].lower()\n",
    "            self.rnn = nn.RNN(\n",
    "                embedding_size, \n",
    "                hidden_size, \n",
    "                num_hidden_layers,\n",
    "                batch_first=True, \n",
    "                nonlinearity=nonlinearity,\n",
    "                dropout=dropout\n",
    "            )\n",
    "        else:\n",
    "            self.rnn = getattr(nn, rnn_type)(\n",
    "                embedding_size,\n",
    "                hidden_size,\n",
    "                num_hidden_layers,\n",
    "                batch_first=True,\n",
    "                dropout=dropout\n",
    "            )\n",
    "\n",
    "        self.projection = nn.Linear(hidden_size, vocab_size)\n",
    "\n",
    "    def forward(\n",
    "        self, \n",
    "        input: torch.Tensor,\n",
    "        prev_hidden: Union[torch.Tensor, Tuple[torch.Tensor, torch.Tensor]]\n",
    "    ):\n",
    "        \"\"\" RNN ëª¨ë¸ì˜ forward í•¨ìˆ˜ êµ¬í˜„\n",
    "        ìœ„ì˜ ê·¸ë¦¼ê³¼ __init__ í•¨ìˆ˜ ë‚´ ì£¼ì„ì„ ì°¸ê³ í•˜ì—¬ forward í•¨ìˆ˜ë¥¼ êµ¬í˜„í•˜ì„¸ìš”.\n",
    "\n",
    "        Hint 2: RNN ëª¨ë¸ì—ì„  Dropoutì„ ê³³ê³³ì— ì ìš©í•˜ëŠ” ê²ƒì´ ì„±ëŠ¥ì´ ì¢‹ë‹¤ê³  ì•Œë ¤ì ¸ ìˆìŠµë‹ˆë‹¤.\n",
    "                ì˜ˆë¥¼ ë“¤ì–´, Embedding ì´í›„ì™€ Projection ì „ì—ë„ ì ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "        Hint 2: ìµœì¢… í™•ë¥ ê°’ì„ êµ¬í•˜ê¸° ìœ„í•´ì„œ Projection ì´í›„ì— F.log_softmaxë¥¼ ì‚¬ìš©í•˜ë©´ ë©ë‹ˆë‹¤.\n",
    "\n",
    "        Arguments:\n",
    "        input -- í† í°í™” ë° ë°°ì¹˜í™”ëœ ë¬¸ì¥ë“¤ì˜ í…ì„œ\n",
    "                    dtype: torch.long\n",
    "                    shape: [batch_size, sequence_lentgh]\n",
    "        prev_hidden -- ì´ì „ì˜ hidden state\n",
    "                    dtype: torch.float\n",
    "                    shape: RNN, GRU - [num_layers, batch_size, hidden_size]\n",
    "                           LSTM - ([num_layers, batch_size, hidden_size], [num_layers, batch_size, hidden_size])\n",
    "\n",
    "        Return:\n",
    "        log_prob -- ë‹¤ìŒ í† í°ì„ ì˜ˆì¸¡í•œ í™•ë¥ ì— logë¥¼ ì·¨í•œ ê°’\n",
    "                    dtype: torch.float\n",
    "                    shape: [batch_size, sequence_length, vocab_size]\n",
    "        next_hidden -- ì´í›„ì˜ hidden state\n",
    "                    dtype: torch.float\n",
    "                    shape: RNN, GRU - [num_layers, batch_size, hidden_size]\n",
    "                           LSTM - ([num_layers, batch_size, hidden_size], [num_layers, batch_size, hidden_size])\n",
    "        \"\"\"\n",
    "        ### YOUR CODE HERE\n",
    "        ### ANSWER HERE ###\n",
    "        emb = self.dropout(self.embedding(input))\n",
    "        output, next_hidden = self.rnn(emb, prev_hidden)\n",
    "        log_prob = self.projection(self.dropout(output)).log_softmax(dim=-1)\n",
    "\n",
    "        ### END YOUR CODE\n",
    "        \n",
    "        assert list(log_prob.shape) == list(input.shape) + [self.vocab_size]\n",
    "        assert prev_hidden.shape == next_hidden if self.rnn_type != 'LSTM' \\\n",
    "          else prev_hidden[0].shape == next_hidden[0].shape == next_hidden[1].shape\n",
    "        \n",
    "        return log_prob, next_hidden\n",
    "    \n",
    "    def init_hidden(self, batch_size: int):\n",
    "        \"\"\" ì²« hidden stateë¥¼ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜ \"\"\"\n",
    "        \n",
    "        weight = self.projection.weight\n",
    "        \n",
    "        if self.rnn_type == 'LSTM':\n",
    "            return (weight.new_zeros(self.num_hidden_layer, batch_size, self.hidden_size),\n",
    "                    weight.new_zeros(self.num_hidden_layer, batch_size, self.hidden_size))\n",
    "        else:\n",
    "            return weight.new_zeros(self.num_hidden_layer, batch_size, self.hidden_size)\n",
    "    \n",
    "    @property\n",
    "    def device(self):   # í˜„ì¬ ëª¨ë¸ì˜ deviceë¥¼ ë°˜í™˜í•˜ëŠ” í”„ë¡œí¼í‹°\n",
    "        return self.projection.weight.device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xnsZkQqUHb6Z"
   },
   "source": [
    "ë§ë­‰ì¹˜ì˜ ë¬¸ì¥ë“¤ì„ ë‹¨ì–´ë‹¨ìœ„ í† í°í™”ë¥¼ í•´ë³´ê³  ë‹¨ì–´ë“¤ì˜ ê°œìˆ˜ë¥¼ ì„¸ì–´ë³´ê² ìŠµë‹ˆë‹¤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2aSB9Hk4HjyO",
    "outputId": "f7e2a79f-c13d-483e-b518-e532067ba8c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33278\n"
     ]
    }
   ],
   "source": [
    "corpus = Corpus('/opt/ml/RNN_homework/')\n",
    "vocab_size = len(corpus.dictionary)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OBkvRpEcKEvd"
   },
   "source": [
    "ì´ì „ ê³¼ì œì— ì‚¬ìš©ëœ ì„ë² ë”©ì˜ í¬ê¸°ëŠ” 200ì´ë¯€ë¡œ ë‹¨ì–´ ì„ë² ë”©ì— ì‚¬ìš©ëœ ë§¤ê°œë³€ìˆ˜ì˜ ìˆ˜ëŠ” 33278 x 200 (6,655,600ê°œ)ì…ë‹ˆë‹¤.\n",
    "ê·¸ë ‡ë‹¤ë©´, RNN ëª¨ë¸ì— ì‚¬ìš©ë˜ëŠ” weightì˜ parameter ê°œìˆ˜ëŠ” ëª‡ê°œì¸ì§€ ê°„ë‹¨í•œ í•¨ìˆ˜ë¥¼ ì´ìš©í•´ í™•ì¸í•´ë³´ê² ìŠµë‹ˆë‹¤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "id": "rGjG2j-fKbJu"
   },
   "outputs": [],
   "source": [
    "model = RNNModel('RNN_TANH', vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yTiKccVXLrvx",
    "outputId": "d45f322e-9f5b-45eb-ad52-c9b408f617eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word embedding parameter ê°œìˆ˜: 6655600\n",
      "RNN parameter ê°œìˆ˜: 160800\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"Word embedding parameter ê°œìˆ˜: {count_parameters(model.embedding)}\")\n",
    "print(f\"RNN parameter ê°œìˆ˜: {count_parameters(model.rnn)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nlUFvgTNM1Od"
   },
   "source": [
    "ğŸ’¡ RNN ì¸µì˜ ë§¤ê°œë³€ìˆ˜ ê°œìˆ˜ì™€, ì„ë² ë”© ë§¤ê°œë³€ìˆ˜ ê°œìˆ˜ë¥¼ ë¹„êµí•´ë³´ë©´ ì„ë² ë”© ë§¤ê°œë³€ìˆ˜ì˜ ê°œìˆ˜ê°€ RNNì¸µì˜ ë§¤ê°œë³€ìˆ˜ ìˆ˜ë³´ë‹¤ ì••ë„ì ìœ¼ë¡œ ë§ìŠµë‹ˆë‹¤.\n",
    "\n",
    "ë‹¨ì–´ë‹¨ìœ„ ì„ë² ë”©ì„ ì‚¬ìš©í•˜ëŠ” ê²½ìš° í•™ìŠµì— ì‚¬ìš©ë˜ëŠ” ë§ë­‰ì¹˜ì˜ í¬ê¸°ê°€ ì»¤ì§ˆìˆ˜ë¡ ë“±ì¥í•˜ëŠ” ë‹¨ì–´ê°€ ë”ë”ìš± ë§ì•„ì ¸ ì„ë² ë”©ì˜ ë§¤ê°œë³€ìˆ˜ëŠ” ë” ì»¤ì§€ê²Œ ë˜ê³  ì „ì²´ ë§¤ê°œë³€ìˆ˜ ëŒ€ë¹„ ë‹¨ì–´ ì„ë² ë”©ì´ ì°¨ì§€í•˜ëŠ” ë¹„ì¤‘ì€ ë§¤ìš° ë†’ì•„ì§‘ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o7WfyYBrPpca"
   },
   "source": [
    "âœ¨ ì´ëŸ° ë§¤ê°œë³€ìˆ˜ ë¹„ì¤‘ì˜ ë¹„ëŒ€ì¹­ì„±ì„ í•´ê²°í•˜ê¸° ìœ„í•´ ì²˜ìŒì—ëŠ” ë¬¸ìë‹¨ìœ„ í† í°í™”(character-level tokenization) ë°©ë²•ì´ ì£¼ëª©ì„ ë°›ì•˜ìŠµë‹ˆë‹¤. \n",
    "ë§ ê·¸ëŒ€ë¡œ í•˜ë‚˜ì˜ ê¸€ìë¥¼ ê¸°ì¤€ìœ¼ë¡œ í† í°í™”ì„ í•˜ëŠ”ê±´ë°ìš”.\n",
    "ì´ì „ ì˜ˆì‹œë¥¼ ë¬¸ìë‹¨ìœ„ í† í°í™”ë¥¼ í•˜ë©´ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.\n",
    "\n",
    "\"I have a meal\" -> ['I', 'h', 'a', 'v', 'e', 'a', 'm', 'e', 'a', 'l']\n",
    "\"ë‚˜ëŠ” ë°¥ì„ ë¨¹ëŠ”ë‹¤\" -> ['ë‚˜', 'ëŠ”', 'ë°¥', 'ì„', 'ë¨¹', 'ëŠ”', 'ë‹¤']\n",
    "\n",
    "ê·¸ëŸ¬ë‚˜, ë¬¸ìë‹¨ìœ„ í† í°í™” ì—­ì‹œ ì§€ë‚˜ì¹˜ê²Œ ê¸´ Sequence ê¸¸ì´, ì„±ëŠ¥ ì €í•˜ ë“±ì˜ ë¬¸ì œë¥¼ ê²ªìœ¼ë©° ì„œë¸Œì›Œë“œ í† í°í™”ê°€ ê°ê´‘ì„ ë°›ê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZBI03OI1o41w"
   },
   "source": [
    "ğŸ’¡ì„œë¸Œì›Œë“œ í† í°í™”ê°€ ê°€ì§€ëŠ” ë‘ë²ˆì§¸ ì¥ì ì€ Out-of-Vocabulary (OoV) ë¬¸ì œê°€ ì—†ë‹¤ëŠ” ì ì…ë‹ˆë‹¤.\n",
    "\n",
    "í•™ìŠµ ë°ì´í„°ì—ì„œ ë“±ì¥í•˜ì§€ ì•Šì€ ë‹¨ì–´ëŠ” ëª¨ë‘ Unknown í† í° [UNK]ë¡œ ì²˜ë¦¬ë©ë‹ˆë‹¤. ì´ëŠ” í…ŒìŠ¤íŠ¸ ê³¼ì • ì¤‘ì— ì²˜ìŒ ë³´ëŠ” ë‹¨ì–´ë¥¼ ëª¨ë‘ [UNK]ë¡œ ëª¨ë¸ì˜ ì…ë ¥ì„ ë„£ê²Œ ë˜ë©´ì„œ ì „ì²´ì ìœ¼ë¡œ ëª¨ë¸ì˜ ì„±ëŠ¥ì´ ì €í•˜ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "ê·¸ëŸ¬ë‚˜ ì„œë¸Œì›Œë“œ ë‹¨ìœ„ë¡œ ìë¥´ê²Œ ëœë‹¤ë©´ ìµœì•…ì˜ ê²½ìš°ì—ë„ ë¬¸ìë‹¨ìœ„ë¡œ í† í°í™”ê°€ ì§„í–‰ë©ë‹ˆë‹¤. ì´ëŠ” ì„œë¸Œì›Œë“œ í† í°í™”ëŠ” í˜„ì¬ ê°€ì§€ê³  ìˆëŠ” Vocabìœ¼ë¡œ í•´ë‹¹ ë‹¨ì–´ê°€ í† í°í™”í•  ìˆ˜ ì—†ë‹¤ë©´ ê·¸ ë‹¨ì–´ë¥¼ ì„œë¸Œì›Œë“œ ë‹¨ìœ„ë¡œ ìª¼ê°œ í‰ê°€í•˜ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.\n",
    "\n",
    "ë”°ë¼ì„œ ì„œë¸Œì›Œë“œ í† í°í™”ê¸°ëŠ” ê°€ì¥ ì‘ì€ ë¬¸ì ë‹¨ìœ„ë¡œ ì„œë¸Œì›Œë“œ í† í°í™”ê°€ ê°€ëŠ¥í•˜ê¸° ë•Œë¬¸ì— OoV ë¬¸ì œê°€ ë°œìƒí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jVbjVR3Io41w"
   },
   "source": [
    "### 2. Byte Pair Encoding (BPE)\n",
    "> ì´ ì„¹í„°ì—ì„œëŠ” íŒŒì´ì¬ í‘œì¤€ ë¼ì´ë¸ŒëŸ¬ë¦¬ (Python Standard Library)ë§Œ ì‚¬ìš©í•˜ì„¸ìš”.\n",
    "\n",
    "ëŒ€í‘œì ì¸ ì„œë¸Œì›Œë“œ í† í°í™” ë°©ë²•ì¸ Byte pair encodingì„ êµ¬í˜„í•´ë´…ì‹œë‹¤. BPEì˜ ì •í™•í•œ ì•Œê³ ë¦¬ì¦˜ì€ [ë…¼ë¬¸](https://arxiv.org/pdf/1508.07909.pdf)ì˜ 3í˜ì´ì§€ algorithm 1ì— ì œì‹œë˜ì–´ ìˆìŠµë‹ˆë‹¤. ê° ë¬¸í•­ê³¼ ì£¼ì„ì˜ ì§€ì‹œì‚¬í•­ì„ í™•ì¸í•˜ê³  BPEë¥¼ êµ¬í˜„í•´ë³´ì„¸ìš”.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K73a8sreo41x"
   },
   "source": [
    "### 2-A) BPE Vocab ë§Œë“¤ê¸°\n",
    "\n",
    "BPEì˜ Vocabì„ ë§Œë“œëŠ” ê²ƒì€ ê°„ë‹¨í•©ë‹ˆë‹¤. ë‹¨ìˆœíˆ ê°€ì¥ ë§ì´ ë“±ì¥í•˜ëŠ” ì—°ì†í•œ ì§ì„ ì°¾ì•„ ì¶”ê°€í•˜ëŠ” ê²ƒ ì…ë‹ˆë‹¤.\n",
    "ë‹¤ìŒê³¼ ê°™ì€ ë§ë­‰ì¹˜ê°€ ìˆë‹¤ê³  ê°€ì •í•´ ë´…ì‹œë‹¤.\n",
    "\n",
    "```\n",
    "low lower lowest newest\n",
    "```\n",
    "\n",
    "ìš°ì„ ì€ ê³µë°±ì„ ì œì™¸í•œ ëª¨ë“  ë¬¸ìë¥¼ Vocabì— ì¶”ê°€í•˜ê³  ê° ë‹¨ì–´ì˜ ëì— WORD_END \"`_`\" ë¶™ì—¬ ë‹¨ì–´ë¥¼ êµ¬ë¶„ì§€ì–´ ë´…ì‹œë‹¤.\n",
    "\n",
    "```\n",
    "Vocab: d e i l n o r s t w _\n",
    "[ l o w _ ], [ l o w e r _ ], [ l o w e s t _ ], [ w i d e s t _ ]  \n",
    "```\n",
    "\n",
    "ì´ë•Œ ê°€ì¥ ë§ì´ ë“±ì¥í•œ ì—°ì†í•œ ë‘ í† í°ì„ ì°¾ì•„ Vocabì— ì¶”ê°€í•˜ê³  ë‘ í† í°ì„ ë¶™ì…ë‹ˆë‹¤. ì´ ê²½ìš°ì—ëŠ” `l o`ê°€ ì„¸ë²ˆ ë“±ì¥í•˜ì—¬ ê°€ì¥ ë§ì•˜ìœ¼ë‹ˆ `lo`ë¡œ ë¶™ì—¬ Vocabì— ì¶”ê°€í•©ë‹ˆë‹¤.\n",
    "\n",
    "```\n",
    "Vocab: d e i l n o r s t w _ lo\n",
    "[ lo w _ ], [ lo w e r _ ], [ lo w e s t _ ], [ w i d e s t _ ] \n",
    "```\n",
    "\n",
    "ë‹¤ìŒì€ `lo w`ê°€ ì„¸ë²ˆ ë“±ì¥í•˜ë¯€ë¡œ `low`ë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤.\n",
    "\n",
    "```\n",
    "Vocab: d e i l n o r s t w _ lo low\n",
    "[ low _ ], [ low e r _ ], [ low e s t _ ], [ w i d e s t _ ] \n",
    "```\n",
    "\n",
    "ë‹¤ìŒì€ `e s`ê°€ ë‘ë²ˆ ë“±ì¥í•˜ë¯€ë¡œ `es`ë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤.\n",
    "\n",
    "```\n",
    "Vocab: d e i l n o r s t w _ lo low es\n",
    "[ low _ ], [ low e r _ ], [ low es t _ ], [ w i d es t _ ] \n",
    "```\n",
    "\n",
    "ë‹¤ìŒì€ `es t`ê°€ ë‘ë²ˆ ë“±ì¥í•˜ë¯€ë¡œ `est`ë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤.\n",
    "\n",
    "```\n",
    "Vocab: d e i l n o r s t w _ lo low es est\n",
    "[ low _ ], [ low e r _ ], [ low est _ ], [ w i d est _ ] \n",
    "```\n",
    "\n",
    "ë‹¤ìŒì€ `est _`ê°€ ë‘ë²ˆ ë“±ì¥í•˜ë¯€ë¡œ `est_`ë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤.\n",
    "\n",
    "```\n",
    "Vocab: d e i l n o r s t w _ lo low es est est_\n",
    "[ low _ ], [ low e r _ ], [ low est_ ], [ w i d est_ ] \n",
    "```\n",
    "\n",
    "`est_`ëŠ” estë¡œ ë‹¨ì–´ê°€ ëë‚œë‹¤ëŠ” ê²ƒì„ ì•Œë ¤ì£¼ëŠ” ì„œë¸Œì›Œë“œê°€ ë©ë‹ˆë‹¤. ì¼ë°˜ì ìœ¼ë¡œ estê°€ ë‚˜ì˜¤ë©´ ë‹¨ì–´ê°€ ëë‚˜ë‹ˆ í•©ë¦¬ì ì…ë‹ˆë‹¤.\n",
    "\n",
    "ì´ëŸ¬í•œ ê³¼ì •ì„ í†µí•´ì„œ ëª¨ë“  ë‹¨ì–´ê°€ ì¶”ê°€ë˜ê±°ë‚˜ ì›í•˜ëŠ” Vocab í¬ê¸°ì— ë„ë‹¬í•  ë•Œê¹Œì§€ ì„œë¸Œì›Œë“œë¥¼ í†µí•©í•˜ì—¬ ì¶”ê°€í•˜ëŠ” ê³¼ì •ì„ ë°˜ë³µí•˜ë©´ ë©ë‹ˆë‹¤. ì•Œê³ ë¦¬ì¦˜ì„ ì°¸ê³ í•˜ì—¬ `build_bpe`ë¥¼ ì‘ì„±í•´ ë´…ì‹œë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "id": "No6tMv2co41x"
   },
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import collections, re\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ë‹¨ì–´ ëì„ ë‚˜íƒ€ë‚´ëŠ” ë¬¸ì\n",
    "WORD_END = '_'\n",
    "\n",
    "def build_bpe(\n",
    "    corpus: List[str],\n",
    "    max_vocab_size: int\n",
    ") -> List[int]:\n",
    "    \"\"\" BPE Vocab ë§Œë“¤ê¸°\n",
    "    Byte Pair Encodingì„ í†µí•œ Vocab ìƒì„±ì„ êµ¬í˜„í•˜ì„¸ìš”.\n",
    "    ë‹¨ì–´ì˜ ëì€ '_'ë¥¼ ì‚¬ìš©í•´ ì£¼ì„¸ìš”.\n",
    "    ì´ë•Œ id2tokenì„ ì„œë¸Œì›Œë“œê°€ ê¸´ ê¸¸ì´ ìˆœìœ¼ë¡œ ì •ë ¬í•´ ì£¼ì„¸ìš”.\n",
    "    \n",
    "    Note: ë§Œì•½ ëª¨ë“  ë‹¨ì–´ì— ëŒ€í•´ BPE ì•Œê³ ë¦¬ì¦˜ì„ ëŒë¦¬ê²Œ ë˜ë©´ ë§¤ìš° ë¹„íš¨ìœ¨ì ì…ë‹ˆë‹¤.\n",
    "          ì™œëƒí•˜ë©´ ëŒ€ë¶€ë¶„ì˜ ë‹¨ì–´ëŠ” ì¤‘ë³µë˜ê¸° ë•Œë¬¸ì— ì¤‘ë³µë˜ëŠ” ë‹¨ì–´ì— ëŒ€í•´ì„œëŠ” í•œë²ˆë§Œ ì—°ì‚°í•  ìˆ˜ ìˆë‹¤ë©´ ë§¤ìš° íš¨ìœ¨ì ì´ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.\n",
    "          ë”°ë¼ì„œ collections ë¼ì´ë¸ŒëŸ¬ë¦¬ì˜ Counterë¥¼ í™œìš©í•´ ê° ë‹¨ì–´ì˜ ë¹ˆë„ë¥¼ êµ¬í•˜ê³ ,\n",
    "          ê° ë‹¨ì–´ì— ë¹ˆë„ë¥¼ ê°€ì¤‘ì¹˜ë¡œ í™œìš©í•˜ì—¬ BPEë¥¼ ëŒë¦¬ë©´ ì‹œê°„ì„ íšê¸°ì ìœ¼ë¡œ ì¤„ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "          ë¬¼ë¡  ì´ëŠ” Optionalí•œ ìš”ì†Œì…ë‹ˆë‹¤.\n",
    "\n",
    "    Arguments:\n",
    "    corpus -- Vocabì„ ë§Œë“¤ê¸° ìœ„í•œ ë‹¨ì–´ ë¦¬ìŠ¤íŠ¸\n",
    "    max_vocab_size -- ìµœëŒ€ vocab í¬ê¸°\n",
    "\n",
    "    Return:\n",
    "    id2token -- ì„œë¸Œì›Œë“œ Vocab. ë¬¸ìì—´ ë¦¬ìŠ¤íŠ¸ í˜•íƒœë¡œ idë¡œ tokenì„ ì°¾ëŠ” ë§¤í•‘ìœ¼ë¡œë„ í™œìš© ê°€ëŠ¥\n",
    "    \"\"\"\n",
    "    ### YOUR CODE HERE\n",
    "    def get_stats(vocab):\n",
    "        pairs=collections.defaultdict(int)\n",
    "        for word,freq in vocab.items():\n",
    "            word=word.split(' ')\n",
    "            for i in range(len(word)-1):\n",
    "                pairs[word[i]+word[i+1]] +=freq\n",
    "\n",
    "        return pairs\n",
    "\n",
    "    def merge_vocab(vocab,pair):\n",
    "        v_out={}\n",
    "        for word,freq in vocab.items():\n",
    "            word_list=word.split(' ')\n",
    "            for i in range(len(word_list)-1):\n",
    "                if pair == word_list[i]+word_list[i+1]:\n",
    "                    sub=word_list[i]+' '+word_list[i+1]\n",
    "                    word= word.replace(sub,pair)\n",
    "                    break\n",
    "            \n",
    "            if word not in v_out:\n",
    "                v_out[word]=freq\n",
    "            else:\n",
    "                v_out[word]+= freq\n",
    "\n",
    "        return v_out\n",
    "    \n",
    "    corpus= Counter(corpus)\n",
    "    vocab={}\n",
    "    \n",
    "    for word, freq in corpus.items():\n",
    "        s=''\n",
    "        for letter in word:\n",
    "            s+=letter\n",
    "            s+=' '\n",
    "        s+=('_')\n",
    "        vocab[s] = freq\n",
    "        \n",
    "      \n",
    "    id2token=[]\n",
    "    id2token.append('_')\n",
    "    for word in set(corpus):\n",
    "        for letter in word:\n",
    "            if letter not in id2token and letter != ' ':\n",
    "                id2token.append(letter)    \n",
    "    while len(id2token) < max_vocab_size:\n",
    "        pairs= get_stats(vocab)\n",
    "        if len(pairs) ==0 :\n",
    "            break\n",
    "        if len(pairs) ==1 :\n",
    "            best=list(pairs.keys())[0]\n",
    "        else:\n",
    "            \n",
    "            best=max(pairs, key= pairs.get)        \n",
    "        vocab=merge_vocab(vocab,best)\n",
    "        if best not in id2token:\n",
    "            id2token.append(best)\n",
    "\n",
    "    \n",
    "\n",
    "    ### ANSWER HERE ###\n",
    "\n",
    "    ### END YOUR CODE\n",
    "    id2token = sorted(id2token,key=len, reverse=True)\n",
    "    \n",
    "    \n",
    "    \n",
    "    return id2token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t0BjnNpgo41x"
   },
   "source": [
    "**2-A ë¬¸ì œì— ëŒ€í•œ í…ŒìŠ¤íŠ¸ ì½”ë“œ**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 418
    },
    "id": "zKMn_ivmo41x",
    "outputId": "32433222-308d-4700-f0c8-4863b3ecad75"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======Building BPE Vocab Test Case======\n",
      "ì²«ë²ˆì§¸ í…ŒìŠ¤íŠ¸ í†µê³¼!\n",
      "ë‘ë²ˆì§¸ í…ŒìŠ¤íŠ¸ í†µê³¼!\n",
      "ì„¸ë²ˆì§¸ í…ŒìŠ¤íŠ¸ í†µê³¼!\n",
      "ë„¤ë²ˆì§¸ í…ŒìŠ¤íŠ¸ í†µê³¼!\n",
      "ëª¨ë“  í…ŒìŠ¤íŠ¸ í†µê³¼!\n"
     ]
    }
   ],
   "source": [
    "print (\"======Building BPE Vocab Test Case======\")\n",
    "\n",
    "# ì²«ë²ˆì§¸ í…ŒìŠ¤íŠ¸\n",
    "corpus = ['abcde']\n",
    "vocab = build_bpe(corpus, max_vocab_size=15)\n",
    "assert sorted(vocab, key=len, reverse=True) == vocab, \\\n",
    "       \"id2tokenì„ ì„œë¸Œì›Œë“œ ê¸¸ì´ê°€ ê¸´ ìˆœìœ¼ë¡œ ì •ë ¬í•´ ì£¼ì„¸ìš”.\"\n",
    "print(\"ì²«ë²ˆì§¸ í…ŒìŠ¤íŠ¸ í†µê³¼!\")\n",
    "\n",
    "# ë‘ë²ˆì§¸ í…ŒìŠ¤íŠ¸\n",
    "corpus = ['low'] * 5 + ['lower'] * 2 + ['newest'] * 6 + ['widest'] * 3\n",
    "vocab = set(build_bpe(corpus, max_vocab_size=19))\n",
    "assert vocab > {'est_', 'low', 'newest_', \\\n",
    "              'i', 'e', 'n', 't', 'd', 's', 'o', 'l', 'r', 'w', WORD_END} and \\\n",
    "       \"low_\" not in vocab and \"wi\" not in vocab and \"id\" not in vocab, \\\n",
    "       \"BPE ê²°ê³¼ê°€ ê¸°ëŒ€í•œ ê²°ê³¼ì™€ ë‹¤ë¦…ë‹ˆë‹¤.\"\n",
    "print(\"ë‘ë²ˆì§¸ í…ŒìŠ¤íŠ¸ í†µê³¼!\")\n",
    "\n",
    "# ì„¸ë²ˆì§¸ í…ŒìŠ¤íŠ¸\n",
    "corpus = ['aaaaaaaaaaaa', 'abababab']\n",
    "vocab = set(build_bpe(corpus, max_vocab_size=8))\n",
    "assert vocab == {'aaaaaaaa', 'aaaa', 'abab', 'aa', 'ab', 'a', 'b', WORD_END}, \\\n",
    "       \"BPE ê²°ê³¼ê°€ ê¸°ëŒ€í•œ ê²°ê³¼ì™€ ë‹¤ë¦…ë‹ˆë‹¤.\"\n",
    "print(\"ì„¸ë²ˆì§¸ í…ŒìŠ¤íŠ¸ í†µê³¼!\")\n",
    "\n",
    "# ë„¤ë²ˆì§¸ í…ŒìŠ¤íŠ¸\n",
    "corpus = ['abc', 'bcd']\n",
    "vocab = build_bpe(corpus, max_vocab_size=10000)\n",
    "assert len(vocab) == 10, \\\n",
    "       \"BPE ê²°ê³¼ê°€ ê¸°ëŒ€í•œ ê²°ê³¼ì™€ ë‹¤ë¦…ë‹ˆë‹¤.\"\n",
    "print(\"ë„¤ë²ˆì§¸ í…ŒìŠ¤íŠ¸ í†µê³¼!\")\n",
    "\n",
    "print(\"ëª¨ë“  í…ŒìŠ¤íŠ¸ í†µê³¼!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kd9wdWpgo41y"
   },
   "source": [
    "### 2-B) BPE ì¸ì½”ë”©\n",
    "ë§Œë“¤ì–´ì§„ Vocabìœ¼ë¡œ í…ìŠ¤íŠ¸ ì¸ì½”ë”©í•˜ëŠ” ë°©ë²•ì€ ëª‡ ê°€ì§€ê°€ ìˆìŠµë‹ˆë‹¤. ê°€ì¥ ì‰¬ìš´ ë°©ë²•ì€ ì•ì—ì„œë¶€í„° í† í°í™”í•˜ë˜ ê°€ì¥ ê¸´ ê²ƒë¶€í„° ìš•ì‹¬ìŸì´ ê¸°ë²•(Greedy Search)ìœ¼ë¡œ ë¨¼ì € ë§¤ì¹­í•˜ëŠ” ë°©ë²•ì…ë‹ˆë‹¤.\n",
    "\n",
    "```\n",
    "Vocab: bcde ab cd bc de a b c d e _\n",
    "abcde ==> ab cd e _\n",
    "```\n",
    "\n",
    "ì´ ë°©ë²•ì€ ìµœì ì˜ ì¸ì½”ë”©ì„ ë³´ì¥í•˜ì§„ ì•Šì§€ë§Œ ê¸´ ë‹¨ì–´ë¥¼ ë¹ ë¥´ê²Œ ì¸ì½”ë”©í•˜ëŠ” ê²ƒì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.\n",
    "\n",
    "ë‘ë²ˆì§¸ ë°©ë²•ì€ ê°€ì¥ ê¸¸ê²Œ ë§¤ì¹­ë˜ëŠ” ê²ƒì„ ì „ì²´ í…ìŠ¤íŠ¸ì— ëŒ€í•´ ë¨¼ì € í† í°í™”í•˜ëŠ” ë°©ë²•ì…ë‹ˆë‹¤.\n",
    "\n",
    "```\n",
    "Vocab: bcde ab cd bc de a b c d e _\n",
    "abcde ==> a bcde _\n",
    "```\n",
    "\n",
    "ë‘ë²ˆì§¸ ë°©ë²•ì€ ì²«ë²ˆì§¸ ë°©ë²•ë³´ë‹¤ ëŠë¦¬ì§€ë§Œ í…ìŠ¤íŠ¸ë¥¼ ì¢€ ë” ì§§ê²Œ ì¸ì½”ë”©í•˜ëŠ” ê²ƒì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.\n",
    "\n",
    "ì´ ê³¼ì œì—ì„œëŠ” ë‘ë²ˆì§¸ ë°©ë²•ì„ ì´ìš©í•˜ì—¬ BPE ì¸ì½”ë”©ì„ êµ¬í˜„í•´ë´…ì‹œë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "id": "uLHKx2Qho41y"
   },
   "outputs": [],
   "source": [
    "def encode(\n",
    "    sentence: str,\n",
    "    id2token: List[str]\n",
    ") -> List[int]:\n",
    "    \"\"\" BPE ì¸ì½”ë”\n",
    "    ë¬¸ì¥ì„ ë°›ì•„ BPE í† í°í™”ë¥¼ í†µí•˜ì—¬ ê³ ìœ  idì˜ ìˆ˜ì—´ë¡œ ë°”ê¿‰ë‹ˆë‹¤.\n",
    "    ë¬¸ì¥ì€ ê³µë°±ìœ¼ë¡œ ë‹¨ì–´ë‹¨ìœ„ í† í°í™”ë˜ì–´ìˆë‹¤ê³  ê°€ì •í•˜ë©°, Vocabì€ sentenceì˜ ëª¨ë“  ë¬¸ìë¥¼ í¬í•¨í•œë‹¤ê³  ê°€ì •í•©ë‹ˆë‹¤.\n",
    "    ì°¾ì„ ìˆ˜ ìˆëŠ” ê°€ì¥ ê¸´ í† í°ë¶€í„° ë°”ê¿‰ë‹ˆë‹¤.\n",
    "    \n",
    "    Note: WORD_ENDë¥¼ ë¹¼ë¨¹ì§€ ë§ˆì„¸ìš”.\n",
    "\n",
    "    Arguments:\n",
    "    sentence -- ì¸ì½”ë“œí•˜ê³ ì í•˜ëŠ” ë¬¸ì¥\n",
    "    id2token -- build_bpeë¥¼ í†µí•´ ë§Œë“¤ì–´ì§„ Vocab\n",
    "    \n",
    "    Return:\n",
    "    token_ids -- ì¸ì½”ë“œëœ í† í° id ìˆ˜ì—´\n",
    "    \"\"\"\n",
    "    token_ids=[]\n",
    "    sentences=sentence.split(' ')\n",
    "    for sentence in sentences:\n",
    "        sentence+='_'\n",
    "        for token in vocab:\n",
    "            if token in sentence:\n",
    "                sentence= sentence.replace(token,str(vocab.index(token)))\n",
    "        token_ids+=sentence\n",
    "        \n",
    "        \n",
    "\n",
    "    ### YOUR CODE HERE\n",
    "    ### ANSWER HERE ###\n",
    "\n",
    "    ### END YOUR CODE\n",
    "    for i in range(len(token_ids)):\n",
    "        token_ids[i] = int(token_ids[i])\n",
    "    return token_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f7cHzDETo41y"
   },
   "source": [
    "**2-B ë¬¸ì œì— ëŒ€í•œ í…ŒìŠ¤íŠ¸ ì½”ë“œ**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "id": "lQOt8lz4o41y"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======Encoding Test Case======\n",
      "ì²«ë²ˆì§¸ í…ŒìŠ¤íŠ¸ í†µê³¼!\n",
      "ë‘ë²ˆì§¸ í…ŒìŠ¤íŠ¸ í†µê³¼!\n",
      "ëª¨ë“  í…ŒìŠ¤íŠ¸ í†µê³¼!\n"
     ]
    }
   ],
   "source": [
    "print (\"======Encoding Test Case======\")\n",
    "\n",
    "# ì²«ë²ˆì§¸ í…ŒìŠ¤íŠ¸\n",
    "vocab = ['bcc', 'bb', 'bc', 'a', 'b', 'c', WORD_END]\n",
    "assert encode('abbccc', vocab) == [3, 4, 0, 5, 6], \\\n",
    "       \"BPE ì¸ì½”ë”© ê²°ê³¼ê°€ ê¸°ëŒ€í•œ ê²°ê³¼ì™€ ë‹¤ë¦…ë‹ˆë‹¤.\"\n",
    "print(\"ì²«ë²ˆì§¸ í…ŒìŠ¤íŠ¸ í†µê³¼!\")\n",
    "\n",
    "# Second test\n",
    "vocab = ['aaaa', 'aa', 'a', WORD_END]\n",
    "assert len(encode('aaaaaaaa aaaaaaa', vocab)) == 7, \\\n",
    "       \"BPE ì¸ì½”ë”© ê²°ê³¼ê°€ ê¸°ëŒ€í•œ ê²°ê³¼ì™€ ë‹¤ë¦…ë‹ˆë‹¤.\"\n",
    "print(\"ë‘ë²ˆì§¸ í…ŒìŠ¤íŠ¸ í†µê³¼!\")\n",
    "\n",
    "print(\"ëª¨ë“  í…ŒìŠ¤íŠ¸ í†µê³¼!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1CGfMVhVo41y"
   },
   "source": [
    "### 2-C) BPE ë””ì½”ë”©"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cG8QmbaLo41y"
   },
   "source": [
    "BPEë¡œ ì¸ì½”ë”©ëœ ê²ƒì„ ë””ì½”ë”©í•˜ëŠ” ê²ƒì€ ê°„ë‹¨í•©ë‹ˆë‹¤.\n",
    "ê·¸ì € í•´ë‹¹ idë¥¼ í•´ë‹¹í•˜ëŠ” ì„œë¸Œì›Œë“œë¡œ ë§Œë“  ë’¤ í•©ì¹˜ë©´ë©ë‹ˆë‹¤.\n",
    "WORD_ENDëŠ” ê³µë°±ìœ¼ë¡œ ì²˜ë¦¬í•˜ë©´ ì‰½ìŠµë‹ˆë‹¤.\n",
    "\n",
    "```\n",
    "[ 196 62 20 6 ] ==> [ I_ li ke_ it_ ] ==> \"I_like_it_\" ==> \"I like it \" ==> \"I like it\"  \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "id": "9stE7H6lo41z"
   },
   "outputs": [],
   "source": [
    "def decode(\n",
    "    token_ids: List[int],\n",
    "    id2token: List[str]\n",
    ") -> str:\n",
    "    \"\"\" BPE ë””ì½”ë”\n",
    "    BPEë¡œ í† í°í™”ëœ id ìˆ˜ì—´ì„ ë°›ì•„ ë¬¸ì¥ìœ¼ë¡œ ë°”ê¿‰ë‹ˆë‹¤.\n",
    "    ë‹¨ì–´ë‹¨ìœ„ í† í°í™”ì—ì„œì˜ ë¬¸ì¥ ë³µì›ì€ ë‹¨ìˆœíˆ ê³µë°±ì„ ì‚¬ì´ì— ë„£ëŠ” ë””ì½”ë”©ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
    "    ë¬¸ì¥ ëì˜ ê³µë°±ì€ ì˜ë¼ëƒ…ë‹ˆë‹¤.\n",
    "    \n",
    "    Arguments:\n",
    "    token_ids -- ë””ì½”ë“œí•˜ê³ ìí•˜ëŠ” í† í° id ìˆ˜ì—´\n",
    "    id2token -- build_bpeë¥¼ í†µí•´ ë§Œë“¤ì–´ì§„ Vocab\n",
    "\n",
    "    Return:\n",
    "    sentence  -- ë””ì½”ë“œëœ ë¬¸ì¥\n",
    "    \"\"\"\n",
    "\n",
    "    ### YOUR CODE HERE\n",
    "    ### ANSWER HERE ###\n",
    "    sentence=''\n",
    "    for ids in token_ids:\n",
    "        sentence+=id2token[ids]\n",
    "    \n",
    "    sentences=sentence.replace('_',' ')\n",
    "    \n",
    "    sentences = sentences[:-1]\n",
    "    ### END YOUR CODE\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IAJKJzdMo41z"
   },
   "source": [
    "**2-C ë¬¸ì œì— ëŒ€í•œ í…ŒìŠ¤íŠ¸ ì½”ë“œ**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "id": "XXC9vdLwo41z"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======Decoding Test Case======\n",
      "ì²«ë²ˆì§¸ í…ŒìŠ¤íŠ¸ í†µê³¼!\n",
      "ë‘ë²ˆì§¸ í…ŒìŠ¤íŠ¸ í†µê³¼!\n"
     ]
    }
   ],
   "source": [
    "print (\"======Decoding Test Case======\")\n",
    "# First test\n",
    "vocab = ['bcc', 'bb', 'bc', 'a', 'b', 'c', WORD_END]\n",
    "assert decode([3, 4, 0, 5, 6], vocab) == 'abbccc', \\\n",
    "           \"BPE ë””ì½”ë”© ê²°ê³¼ê°€ ê¸°ëŒ€í•œ ê²°ê³¼ì™€ ë‹¤ë¦…ë‹ˆë‹¤.\"\n",
    "print(\"ì²«ë²ˆì§¸ í…ŒìŠ¤íŠ¸ í†µê³¼!\")\n",
    "\n",
    "# Second test\n",
    "vocab = ['aaaa', 'aa', 'a', WORD_END]\n",
    "assert decode([0, 0, 3, 0, 1, 2, 3], vocab) == 'aaaaaaaa aaaaaaa', \\\n",
    "           \"BPE ë””ì½”ë”© ê²°ê³¼ê°€ ê¸°ëŒ€í•œ ê²°ê³¼ì™€ ë‹¤ë¦…ë‹ˆë‹¤.\"\n",
    "print(\"ë‘ë²ˆì§¸ í…ŒìŠ¤íŠ¸ í†µê³¼!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iNXD4Ml_RVGb"
   },
   "source": [
    "### 3. Transformers ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ í™œìš©í•œ ì„œë¸Œì›Œë“œ í† í°í™”\n",
    "\n",
    "âœ¨ ìœ„ì—ì„œ ì‘ì„±í•œ BPE êµ¬í˜„ì²´ë¥¼ í†µí•´ ì„œë¸Œì›Œë“œ í† í°í™”ì˜ ì›ë¦¬ë¥¼ ì•Œ ìˆ˜ ìˆì§€ë§Œ, ìœ„ì˜ êµ¬í˜„ì²´ë¥¼ ì‹¤ì œë¡œ ì‚¬ìš©í•˜ê¸°ì—ëŠ” ë‚œì ì´ ì¡´ì¬í•©ë‹ˆë‹¤.\n",
    "ì™œëƒí•˜ë©´ BPE Vocabì„ ë§Œë“œëŠ” ê³¼ì •ì€ ë§¤ìš° ì˜¤ëœ ì‹œê°„ì´ ê±¸ë¦¬ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.\n",
    "ë‹¤ì–‘í•œ í† í°í™”ê¸°(tokenizer)ë¥¼ ì§ì ‘ êµ¬í˜„í•˜ê³  í•™ìŠµí•˜ëŠ” ê²ƒì€ ë§¤ìš° ë¹„ìš©ì´ í¬ê¸° ë•Œë¬¸ì—, ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ í™œìš©í•˜ì—¬ í† í°í™”ê¸°ë¥¼ ì‚¬ìš©í•˜ëŠ” ë°©ë²•ì„ ì•Œì•„ë´…ì‹œë‹¤.\n",
    "\n",
    "[Transformer](https://huggingface.co/docs/transformers/index) ë¼ì´ë¸ŒëŸ¬ë¦¬ëŠ” ë‹¤ì–‘í•œ Transformer êµ¬í˜„ì²´ë¥¼ ì´ë§ë¼í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ì…ë‹ˆë‹¤.\n",
    "Transfomer ì™¸ì—ë„ ë‹¤ì–‘í•œ í† í°í™”ê¸°ë¥¼ ì§€ì›í•˜ëŠ”ë°, ì´ë¯¸ í•™ìŠµëœ ì„œë¸Œì›Œë“œ í† í°í™”ê¸° ì—­ì‹œ ì‰½ê²Œ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "(ì°¸ê³ 5: [Huggingface: subword tokenization](https://huggingface.co/transformers/tokenizer_summary.html#subword-tokenization))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "id": "vEfuauieo41z"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.8/site-packages (4.17.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.8/site-packages (from transformers) (4.51.0)\n",
      "Requirement already satisfied: sacremoses in /opt/conda/lib/python3.8/site-packages (from transformers) (0.0.47)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /opt/conda/lib/python3.8/site-packages (from transformers) (0.4.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.8/site-packages (from transformers) (2.24.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.8/site-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.8/site-packages (from transformers) (21.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.8/site-packages (from transformers) (5.3.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,>=0.11.1 in /opt/conda/lib/python3.8/site-packages (from transformers) (0.11.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.8/site-packages (from transformers) (2022.3.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.8/site-packages (from transformers) (1.19.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.7.4.3)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging>=20.0->transformers) (2.4.7)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.8/site-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests->transformers) (1.25.11)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests->transformers) (2020.12.5)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.8/site-packages (from sacremoses->transformers) (1.0.1)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.8/site-packages (from sacremoses->transformers) (1.15.0)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.8/site-packages (from sacremoses->transformers) (8.0.4)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: You are using pip version 22.0.3; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the '/opt/conda/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "id": "WZKyn3PKUuBg"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizerFast\n",
    "\n",
    "# BERT ëª¨ë¸ì—ì„œ ì‚¬ìš©í•˜ëŠ” í† í°í™”ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.\n",
    "# https://huggingface.co/docs/transformers/model_doc/bert#transformers.BertTokenizerFast\n",
    "tokenizer = BertTokenizerFast.from_pretrained(\n",
    "    \"bert-base-cased\",\n",
    "    unk_token='<unk>',\n",
    "    eos_token='<eos>'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4KCFLlSBo41z"
   },
   "source": [
    "**Question**\n",
    "\n",
    "Transformersì—ì„œ ì œê³µë˜ëŠ” BertTokenizerFastëŠ” ëª¨ë“  ì¡°í•©ì„ ë§Œë“¤ ìˆ˜ ìˆëŠ” ì„œë¸Œì›Œë“œ ê¸°ë°˜ í† í°í™”ê¸°ì„ì—ë„ ë¶ˆêµ¬í•˜ê³  ìœ„ì™€ ê°™ì´ Unknown í† í°ì„ ë°›ì„ ìˆ˜ ìˆë‹¤. ì„œë¸Œì›Œë“œ í† í°í™”ê¸°ì—ì„œ Unknown í† í°ì´ ë°œìƒí•  ìˆ˜ ìˆëŠ” ìƒí™©ì€ ë¬´ì—‡ì´ ìˆì„ê¹Œ?\n",
    "\n",
    "**Answer**\n",
    "\n",
    "í† í°ì´ vocabularyì— ì¡´ì¬í•˜ì§€ ì•ŠëŠ”ê²½ìš° unk í† í°ì„ ë°›ëŠ”ë‹¤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "id": "rwubp25xVUt2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Bo', '##ost', '##cam', '##p', 'AI', 'Tech']\n",
      "[9326, 15540, 24282, 1643, 19016, 7882]\n",
      "Boostcamp AI Tech\n",
      "['q', '##wer', '##k', '##l', '##h', '##fa', 'as', '##d', '##f', '##k', '##we', '##j', 'ads', '##fe', '##s', '##d', '##ff']\n",
      "[186, 12097, 1377, 1233, 1324, 8057, 1112, 1181, 2087, 1377, 7921, 3361]\n",
      "qwerklhfa asdfkwej\n"
     ]
    }
   ],
   "source": [
    "# ì„œë¸Œì›Œë“œ í† í°í™” ì˜ˆì‹œ\n",
    "print(tokenizer.tokenize('Boostcamp AI Tech'))\n",
    "token_ids = tokenizer(\"Boostcamp AI Tech\", add_special_tokens=False).input_ids\n",
    "print(token_ids)\n",
    "print(tokenizer.decode(token_ids))\n",
    "\n",
    "print(tokenizer.tokenize('qwerklhfa asdfkwej \\n adsfesdff'))\n",
    "token_ids = tokenizer(\"qwerklhfa asdfkwej\", add_special_tokens=False).input_ids\n",
    "print(token_ids)\n",
    "print(tokenizer.decode(token_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BvtarB2DYiLb"
   },
   "source": [
    "ì´ í† í°í™”ê¸°ëŠ” `##`ì„ í†µí•˜ì—¬ í˜„ ë‹¨ì–´ê°€ ì´ì „ ë‹¨ì–´ì™€ ì—°ê²°ë˜ì–´ ìˆëŠ”ì§€ë¥¼ ì•Œë ¤ì£¼ê³  ìˆìŠµë‹ˆë‹¤. ì´ í† í°í™”ê¸°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë‹¤ì‹œ ëª¨ë¸ì„ ì„ ì–¸í•˜ê³  parameterì˜ ê°œìˆ˜ë¥¼ ì‚´í´ë³´ê² ìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "id": "wLKqis0hY5Or"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28998\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(tokenizer)\n",
    "print(vocab_size)\n",
    "subword_model = RNNModel('RNN_TANH', vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "id": "_RB4DQ-QZCBd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì„ë² ë”© ë§¤ê°œë³€ìˆ˜ ê°œìˆ˜: 5799600\n",
      "RNNì¸µ ë§¤ê°œë³€ìˆ˜ ê°œìˆ˜: 160800\n"
     ]
    }
   ],
   "source": [
    "print(f\"ì„ë² ë”© ë§¤ê°œë³€ìˆ˜ ê°œìˆ˜: {count_parameters(subword_model.embedding)}\")\n",
    "print(f\"RNNì¸µ ë§¤ê°œë³€ìˆ˜ ê°œìˆ˜: {count_parameters(subword_model.rnn)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q_5y4M6k1HR6"
   },
   "source": [
    "ì´ì „ì— ë¹„í•´ ì„ë² ë”© ë§¤ê°œë³€ìˆ˜ ê°œìˆ˜ëŠ” í™•ì—°íˆ ì¤„ì–´ë“¤ì—ˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "6,655,600ê°œ -> 5,799,600ê°œ\n",
    "\n",
    "ê·¸ì— ë¹„í•˜ì—¬ ì´ í† í°í™”ê¸°ëŠ” ì´ì „ í† í°í™”ê¸°ì™€ ë‹¬ë¦¬ í•™ìŠµ ë°ì´í„°ì— ì—†ì—ˆë˜ ì˜ì–´ ë‹¨ì–´ê°€ ìƒˆë¡œ ë‚˜ì˜¤ë”ë¼ë„ í† í°í™”ê°€ ê°€ëŠ¥í•©ë‹ˆë‹¤. \n",
    "\n",
    "ê·¸ëŸ¬ë©´ ì´ì œ ì„œë¸Œì›Œë“œ í† í°í™” ê¸°ë°˜ì˜ ì–¸ì–´ ëª¨ë¸ ì„±ëŠ¥ì„ ì‚´í´ë´…ì‹œë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "md_oQZeso410"
   },
   "source": [
    "### 4. ì„œë¸Œì›Œë“œ ê¸°ë°˜ Language Model í•™ìŠµ\n",
    "ì•ì„œ í™•ì¸í•´ë³¸ `transformers` ë¼ì´ë¸ŒëŸ¬ë¦¬ ê¸°ë°˜ í† í°í™”ê¸°ë¥¼ í™œìš©í•˜ì—¬ ì„œë¸Œì›Œë“œ ê¸°ë°˜ Lanuage Modelì„ í•™ìŠµì‹œì¼œ ë´…ì‹œë‹¤. ê¸°ë³¸ ê³¼ì œ 2ë¥¼ ì°¸ê³ í•˜ì—¬ êµ¬í˜„í•´ë´…ì‹œë‹¤. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "id": "PX2amGs_o410"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (655 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batchifiy done\n",
      "batchifiy done\n",
      "batchifiy done\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2331f38060347e9a1da8f527e628370",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Train'), FloatProgress(value=0.0, max=2230.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "192fe17ae9e04035a63cb6657a1cd06d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Eval'), FloatProgress(value=0.0, max=222.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "| End of epoch  1 | valid loss  5.82 | valid ppl   336.81\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a07a90882b640448fd98dbd8639a48e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Train'), FloatProgress(value=0.0, max=2230.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e34cc3406cb4b72bdfb9e306102743a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Eval'), FloatProgress(value=0.0, max=222.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "| End of epoch  2 | valid loss  5.63 | valid ppl   278.17\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ca75d8330c342df9bebe400544ec940",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Train'), FloatProgress(value=0.0, max=2230.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd5837dc515340e598897ce85d0cb8f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Eval'), FloatProgress(value=0.0, max=222.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "| End of epoch  3 | valid loss  5.54 | valid ppl   254.64\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4fba4fb78f444d48deb6e3f84277714",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Train'), FloatProgress(value=0.0, max=2230.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8123b8e260de4dda944e53892cfdc649",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Eval'), FloatProgress(value=0.0, max=222.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "| End of epoch  4 | valid loss  5.44 | valid ppl   230.80\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ec54b9a1f5541e7bf5a1d33f5bbcdc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Train'), FloatProgress(value=0.0, max=2230.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7488741505a341faa0fae79c977e502c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Eval'), FloatProgress(value=0.0, max=222.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "| End of epoch  5 | valid loss  5.38 | valid ppl   217.46\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77340e13ba934ba3990d12b9274043b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Train'), FloatProgress(value=0.0, max=2230.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac0eaf837b65404781b15bae143a6c27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Eval'), FloatProgress(value=0.0, max=222.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "| End of epoch  6 | valid loss  5.32 | valid ppl   205.29\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "387b75eafb5f45eeaa149d8d82d06622",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Train'), FloatProgress(value=0.0, max=2230.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a0df01edd014241b8a1ac0ee92d8bd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Eval'), FloatProgress(value=0.0, max=222.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "| End of epoch  7 | valid loss  5.30 | valid ppl   200.82\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d344ea0c03b4ea5853e0a0a7861552b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Train'), FloatProgress(value=0.0, max=2230.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "187afafccd844bfcb81e27268a560f3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Eval'), FloatProgress(value=0.0, max=222.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "| End of epoch  8 | valid loss  5.28 | valid ppl   195.88\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52827b9d8f7f46ee8a87b2cc85dcdef6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Train'), FloatProgress(value=0.0, max=2230.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9230f3c8a662458bad5df450f2b8d938",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Eval'), FloatProgress(value=0.0, max=222.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "| End of epoch  9 | valid loss  5.23 | valid ppl   186.21\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9953c1a6c0b4a28afe2212d1dc91ba1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Train'), FloatProgress(value=0.0, max=2230.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9752dfdfa3e7489a8bbf0034eb6301dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Eval'), FloatProgress(value=0.0, max=222.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "| End of epoch 10 | valid loss  5.21 | valid ppl   183.15\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "747583786fdd4c8fa75c4aef52199f64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Train'), FloatProgress(value=0.0, max=2230.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3393899141074fb399053cdd2bd5b842",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Eval'), FloatProgress(value=0.0, max=222.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "| End of epoch 11 | valid loss  5.18 | valid ppl   177.30\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "116cea4c91cb4d889a93708f108ef6e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Train'), FloatProgress(value=0.0, max=2230.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61c2ba75ae31469a8f9d33ef5b9a87f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Eval'), FloatProgress(value=0.0, max=222.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "| End of epoch 12 | valid loss  5.19 | valid ppl   180.02\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd3f30701a6a474fa097e57bd33c0c1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Train'), FloatProgress(value=0.0, max=2230.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "643ca4e8e80f4d45a1ca0e0dc0d9e35b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Eval'), FloatProgress(value=0.0, max=222.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "| End of epoch 13 | valid loss  5.09 | valid ppl   161.84\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30e1422da3b44c79b8ac52954f19ba30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Train'), FloatProgress(value=0.0, max=2230.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e70ba1762a5d4083b9fc6468c3a7a95f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Eval'), FloatProgress(value=0.0, max=222.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "| End of epoch 14 | valid loss  5.08 | valid ppl   161.21\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1529acb40ed84cda89d546fcce990d4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Train'), FloatProgress(value=0.0, max=2230.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17781aaf22a043c0a0d0dab9a2048273",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Eval'), FloatProgress(value=0.0, max=222.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "| End of epoch 15 | valid loss  5.07 | valid ppl   159.61\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "070bfbe6e15f4b1db2ca13d1e64ad7dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Train'), FloatProgress(value=0.0, max=2230.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "190b025bfdbf47fea382bdd446fd7948",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Eval'), FloatProgress(value=0.0, max=222.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "| End of epoch 16 | valid loss  5.06 | valid ppl   157.08\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8500508ace864c72a149380eeadee727",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Train'), FloatProgress(value=0.0, max=2230.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "828af12f4f8d42da8fb3590fe896f029",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Eval'), FloatProgress(value=0.0, max=222.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "| End of epoch 17 | valid loss  5.05 | valid ppl   156.70\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e9ded9399d74fe7a1d88b86a1a5ea5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Train'), FloatProgress(value=0.0, max=2230.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "131c9a5b6c85407a8c490318cd4203dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Eval'), FloatProgress(value=0.0, max=222.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "| End of epoch 18 | valid loss  5.05 | valid ppl   156.75\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f545ecb0c1842e38d701ff0e2a7235d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Train'), FloatProgress(value=0.0, max=2230.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1d879b281d44620880f16e0e27c5785",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Eval'), FloatProgress(value=0.0, max=222.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "| End of epoch 19 | valid loss  5.02 | valid ppl   151.49\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09b03bc79c1445af8d21e647286e2ff2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Train'), FloatProgress(value=0.0, max=2230.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f8d06b8f31d44859790bdb5a5b7d164",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Eval'), FloatProgress(value=0.0, max=222.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "| End of epoch 20 | valid loss  5.00 | valid ppl   149.10\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80a2066aaa7445429aae5ba73e67a9e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Train'), FloatProgress(value=0.0, max=2230.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e292c03ffc1a40c0847b7395d5a34e30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Eval'), FloatProgress(value=0.0, max=222.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "| End of epoch 21 | valid loss  5.00 | valid ppl   149.06\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d22c7b735e444893984cace50e8ebe7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Train'), FloatProgress(value=0.0, max=2230.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00c99c1002494625ab4039fad9f4c189",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Eval'), FloatProgress(value=0.0, max=222.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "| End of epoch 22 | valid loss  5.01 | valid ppl   149.25\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40df7d95ed244735a949c810a3c6a5db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Train'), FloatProgress(value=0.0, max=2230.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0310e5506ef41a18ee79b4130dc0de3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Eval'), FloatProgress(value=0.0, max=222.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "| End of epoch 23 | valid loss  4.98 | valid ppl   145.94\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f54db64542204dc5bd5c9737764f85d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Train'), FloatProgress(value=0.0, max=2230.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fef62f3a09a74e939c19532d50781c5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Eval'), FloatProgress(value=0.0, max=222.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "| End of epoch 24 | valid loss  4.98 | valid ppl   145.80\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b4bf1e2cd994ec983e5dce5404949e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Train'), FloatProgress(value=0.0, max=2230.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ce87aee431c4addb6f7f7e6f2a3a2a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Eval'), FloatProgress(value=0.0, max=222.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "| End of epoch 25 | valid loss  4.98 | valid ppl   145.30\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1abe0bc408264a25b275e9d7052a7262",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Train'), FloatProgress(value=0.0, max=2230.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fc4eb9a6fc64c97a6b4e72d62bea96c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Eval'), FloatProgress(value=0.0, max=222.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "| End of epoch 26 | valid loss  4.98 | valid ppl   145.20\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0afcc0bf9094daaa75b286d87502e2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Train'), FloatProgress(value=0.0, max=2230.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bfd9cf6335c47fbbe119b3ff99cae0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Eval'), FloatProgress(value=0.0, max=222.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "| End of epoch 27 | valid loss  4.98 | valid ppl   144.89\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a64881ace4894181865a34663a55932a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Train'), FloatProgress(value=0.0, max=2230.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f253dd688e9409abf24309fc0a1208f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Eval'), FloatProgress(value=0.0, max=222.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "| End of epoch 28 | valid loss  4.98 | valid ppl   144.96\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fe6964f855e49e782cc7e81200330da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Train'), FloatProgress(value=0.0, max=2230.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0f02b6a56cf4ec5a7415c566cda76a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Eval'), FloatProgress(value=0.0, max=222.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "| End of epoch 29 | valid loss  4.97 | valid ppl   143.74\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a16f2806dec48d3afcf25c402210ce7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Train'), FloatProgress(value=0.0, max=2230.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe0dc5e38638444da50bf7e2a91d98e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Eval'), FloatProgress(value=0.0, max=222.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "| End of epoch 30 | valid loss  4.97 | valid ppl   143.55\n",
      "-----------------------------------------------------------------------------------------\n",
      "Train done!!!!\n"
     ]
    }
   ],
   "source": [
    "### YOUR CODE HERE\n",
    "### ê¸°ë³¸ ê³¼ì œ 2ë¥¼ ì°¸ê³ í•´ì„œ Language model í•™ìŠµ ì½”ë“œë¥¼ ì‘ì„±í•´ ë³´ì„¸ìš”.\n",
    "### ANSWER HERE ###\n",
    "\n",
    "\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "from typing import Union,Tuple\n",
    "from transformers import BertTokenizerFast\n",
    "\n",
    "def bptt_batchify(data,batch_size,sequence_length):\n",
    "    \n",
    "    drop_data_len = len(data)%(batch_size*sequence_length)\n",
    "    data=data[:len(data)-drop_data_len]\n",
    "    data=torch.tensor(data)\n",
    "    data= data.view((batch_size,-1,sequence_length))\n",
    "    batches=np.transpose(data,(1,0,2))\n",
    "    \n",
    "    print('batchifiy done')\n",
    "    return batches\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "def train(model : RNNModel, data : torch.Tensor, lr:float):\n",
    "    model.train()\n",
    "    \n",
    "    batch_size = data.shape[1]\n",
    "    total_loss =0.\n",
    "    hidden = model.init_hidden(batch_size)\n",
    "    progress_bar = tqdm(data,desc=\"Train\")\n",
    "    for bid, batch in enumerate(progress_bar, start=1):\n",
    "        batch=batch.to(model.device)\n",
    "        output,hidden = model(batch,hidden)\n",
    "        if model.rnn_type == 'LSTM':\n",
    "            hidden = tuple(tensor.detach() for tensor in hidden)\n",
    "        else:\n",
    "            hidden = hidden.detach()\n",
    "        loss=F.nll_loss(output[:, :-1, :].transpose(1, 2), batch[:, 1:])\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        clip_grad_norm_(model.parameters(),0.25)\n",
    "        for param in model.parameters():\n",
    "            param.data.add_(param.grad,alpha=-lr)\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        current_loss = total_loss /bid\n",
    "        progress_bar.set_description(f\"Train - loss {current_loss:5.2f} | ppl {math.exp(current_loss):8.2f} | lr {lr:02.2f}\", refresh=False)\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model:RNNModel, data:torch.Tensor):\n",
    "    model.eval()\n",
    "    batch_size=data.shape[1]\n",
    "    total_loss=0\n",
    "    hidden=model.init_hidden(batch_size)\n",
    "    progress_bar = tqdm(data,desc='Eval')\n",
    "    for bid,batch in enumerate(progress_bar, start=1):\n",
    "        batch=batch.to(model.device)\n",
    "        output,hidden=model(batch,hidden)\n",
    "        if model.rnn_type == \"LSTM\":\n",
    "            hidden = tuple(tensor.detach() for tensor in hidden)\n",
    "        else:\n",
    "            hidden = hidden.detach()\n",
    "        \n",
    "        loss = F.nll_loss(output[:, :-1, :].transpose(1, 2), batch[:, 1:])\n",
    "        total_loss += loss.item()\n",
    "        current_loss = total_loss /bid\n",
    "        progress_bar.set_description(f\"Eval - loss {current_loss:5.2f} | ppl {math.exp(current_loss):8.2f}\", refresh=False)\n",
    "    \n",
    "    return loss\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "with open('/opt/ml/RNN_homework/train.txt', 'r', encoding=\"utf8\") as f:\n",
    "    corpus_train = f.readlines()   \n",
    "with open('/opt/ml/RNN_homework/valid.txt', 'r', encoding=\"utf8\") as f:\n",
    "    corpus_val = f.readlines()   \n",
    "with open('/opt/ml/RNN_homework/test.txt', 'r', encoding=\"utf8\") as f:\n",
    "    corpus_test = f.readlines()   \n",
    "    \n",
    "# BERT tokenizer ready\n",
    "tokenizer = BertTokenizerFast.from_pretrained(\n",
    "    \"bert-base-cased\",\n",
    "    unk_token='<unk>',\n",
    "    eos_token='<eos>'\n",
    ")\n",
    "\n",
    "#token to id\n",
    "train_token_ids = sum(tokenizer(corpus_train, add_special_tokens=False).input_ids,[])\n",
    "val_token_ids = sum(tokenizer(corpus_val, add_special_tokens=False).input_ids,[])\n",
    "test_token_ids =  sum(tokenizer(corpus_test, add_special_tokens=False).input_ids,[])\n",
    "#print(tokenizer.decode(token_ids))\n",
    "\n",
    "\n",
    "#datasets ready\n",
    "train_data = bptt_batchify(train_token_ids,batch_size=16,sequence_length=64)\n",
    "val_data = bptt_batchify(val_token_ids,batch_size=16,sequence_length=64)\n",
    "test_data = bptt_batchify(test_token_ids,batch_size=16,sequence_length=64)\n",
    "\n",
    "\n",
    "#model ready###################################\n",
    "vocab_size = len(tokenizer)\n",
    "model = RNNModel('LSTM', vocab_size)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model=model.to(device)\n",
    "\n",
    "\n",
    "#train start\n",
    "lr=20\n",
    "num_epoch=30\n",
    "best_loss=None\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(1,num_epoch+1):\n",
    "    train(model,train_data,lr)\n",
    "    val_loss = evaluate(model,val_data)\n",
    "    print('-' * 89)\n",
    "    print(f'| End of epoch {epoch:2d} | valid loss {val_loss:5.2f} | valid ppl {math.exp(val_loss):8.2f}')\n",
    "    print('-' * 89)\n",
    "    \n",
    "    if not best_loss or val_loss < best_loss:\n",
    "        torch.save(model,'model.pt')\n",
    "        best_loss = val_loss\n",
    "    else:\n",
    "        lr /=4.0\n",
    "\n",
    "print('Train done!!!!')\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "### END YOUR CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gpv4N8wl4w8p"
   },
   "source": [
    "### 5. í•™ìŠµí•œ ì–¸ì–´ ëª¨ë¸ë¡œ ë¬¸ì¥ ìƒì„±\n",
    "\n",
    "ì•ì„œ í•™ìŠµí•œ ëª¨ë¸ì„ ë¶ˆëŸ¬ì™€ì„œ ë¬¸ì¥ì„ ìƒì„±í•´ë´…ì‹œë‹¤.\n",
    "ê¸°ë³¸ ê³¼ì œ 2ì™€ ë˜‘ê°™ì´ generate.txtë¥¼ ì €ì¥í•˜ë©´ ë©ë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "004fe85f1b9a4fd889add3e17c788137",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Eval'), FloatProgress(value=0.0, max=250.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================================================================================\n",
      "| End of training | test loss  5.13 | test ppl   168.97\n",
      "=========================================================================================\n"
     ]
    }
   ],
   "source": [
    "model =torch.load('model.pt', map_location=device)\n",
    "model.rnn.flatten_parameters()\n",
    "test_loss = evaluate(model, test_data)\n",
    "print('=' * 89)\n",
    "print(f'| End of training | test loss {test_loss:5.2f} | test ppl {math.exp(test_loss):8.2f}')\n",
    "print('=' * 89)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "id": "GQjeaKjO4JAh"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5da98c88946e467b8c1366d78efdfe71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Generation'), FloatProgress(value=0.0, max=1000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "### YOUR CODE HERE\n",
    "### ê¸°ë³¸ ê³¼ì œ 2ë¥¼ ì°¸ê³ í•´ì„œ Langauge modelë¡œ ë¬¸ì¥ì„ ìƒì„±í•˜ëŠ” ì½”ë“œë¥¼ ì‘ì„±í•´ ë³´ì„¸ìš”.\n",
    "### ANSWER HERE ###\n",
    "from tqdm.notebook import trange\n",
    "\n",
    "num_words = 1000\n",
    "temperature = 1.0\n",
    "\n",
    "hidden = model.init_hidden(1)\n",
    "input = torch.randint(vocab_size, (1, 1), dtype=torch.long).to(device)\n",
    "outputs = []\n",
    "\n",
    "for i in trange(num_words, desc=\"Generation\"):\n",
    "    with torch.no_grad():\n",
    "        log_prob, hidden = model(input, hidden)\n",
    "\n",
    "    weights = (log_prob.squeeze() / temperature).exp()\n",
    "    token_id = torch.multinomial(weights, 1)\n",
    "    outputs.append(token_id.item())\n",
    "    input = token_id.unsqueeze(0)\n",
    "    \n",
    "outputs =tokenizer.decode(outputs)\n",
    "\n",
    "with open('generate.txt', 'w') as fd:\n",
    "    fd.write(' '.join(outputs).replace('<eos>', '\\n'))\n",
    "\n",
    "### END YOUR CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "[Basic 3] Subword-level Language Model.ipynbì˜ ì‚¬ë³¸",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
