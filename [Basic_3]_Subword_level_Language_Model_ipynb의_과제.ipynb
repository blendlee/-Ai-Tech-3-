{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uOnz8OxdbN3y"
   },
   "source": [
    "# Natural Language Processing\n",
    "\n",
    "## 기본과제 3: Subword-level Language Model\n",
    "\n",
    "> Reference 코드는 Solution 과 함께 공개됩니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NSNON1TAbj2i"
   },
   "source": [
    "### Introduction\n",
    "\n",
    "\n",
    "* 본 과제의 목적은 서브워드 토큰화 (Subword Tokenization)의 필요성을 직접 느끼고 서브워드 토큰화 알고리즘 중 하나인 Byte Pair Encoding을 구현해봅니다.\n",
    "* 서브워트 토큰화 기반 language model을 구현하면서 이전 과제의 Word-level language model과 비교해보는 시간을 갖겠습니다. 추가적으로 RNN을 LSTM으로 변경했을 때의 성능 차이에 대해 살펴보겠습니다.\n",
    "* Subword-level language model을 구현하고, 주어진 데이터를 가공하여 모델을 학습한 후 학습된 언어 모델을 이용해 문장을 생성합니다.\n",
    "* **ANSWER HERE** 이라고 작성된 부분을 채워 완성하시면 됩니다. 다른 부분의 코드를 변경하면 오류가 발생할 수 있습니다.\n",
    "\n",
    "> 과제 완성 후 ipynb 파일을 제출해 주세요.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "70_V429wBxti"
   },
   "source": [
    "### 0. 데이터 업로드\n",
    "\n",
    "\n",
    "1. Boostcourse [기본 과제] Subword-level Language Model 에서 `wikitext-2.zip` 파일을 다운받습니다.\n",
    "2. 본 Colab 환경에 `train.txt`, `dev.txt`, `test.txt` 파일을 업로드합니다.\n",
    "3. `! ls` command 를 실행했을 때, `sample_data  test.txt  train.txt  valid.txt` 가 나오면 성공적으로 데이터 준비가 완료된 것 입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ufq1RSMJo41s",
    "outputId": "4fd66dda-88b6-4554-9e6c-a910f184ca50"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "'[Basic_2]_RNN_based_Language_Model 과제.ipynb'\t\t      practice.ipynb\n",
      "'[Basic_3]_Subword_level_Language_Model_ipynb의_사본.ipynb'   test.txt\n",
      " generate.txt\t\t\t\t\t\t      train.txt\n",
      " model.pt\t\t\t\t\t\t      valid.txt\n"
     ]
    }
   ],
   "source": [
    "! ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AFwHrOCK6UaE",
    "outputId": "24af4031-5121-43f2-8078-fa20838d1bce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36718\n",
      " \n",
      "\n",
      " = Valkyria Chronicles III = \n",
      "\n",
      " \n",
      "\n",
      " Senjō no Valkyria 3 : <unk> Chronicles ( Japanese : 戦場のヴァルキュリア3 , lit . Valkyria of the Battlefield 3 ) , commonly referred to as Valkyria Chronicles III outside Japan , is a tactical role @-@ playing video game developed by Sega and Media.Vision for the PlayStation Portable . Released in January 2011 in Japan , it is the third game in the Valkyria series . <unk> the same fusion of tactical and real @-@ time gameplay as its predecessors , the story runs parallel to the first game and follows the \" Nameless \" , a penal military unit serving the nation of Gallia during the Second Europan War who perform secret black operations and are pitted against the Imperial unit \" <unk> Raven \" . \n",
      "\n",
      " The game began development in 2010 , carrying over a large portion of the work done on Valkyria Chronicles II . While it retained the standard features of the series , it also underwent multiple adjustments , such as making the game more <unk> for series newcomers . Character designer <unk> Honjou and composer Hitoshi Sakimoto both returned from previous entries , along with Valkyria Chronicles II director Takeshi Ozawa . A large team of writers handled the script . The game 's opening theme was sung by May 'n . \n",
      "\n",
      " It met with positive sales in Japan , and was praised by both Japanese and western critics . After release , it received downloadable content , along with an expanded edition in November of that year . It was also adapted into manga and an original video animation series . Due to low sales of Valkyria Chronicles II , Valkyria Chronicles III was not localized , but a fan translation compatible with the game 's expanded edition was released in 2014 . Media.Vision would return to the franchise with the development of Valkyria : Azure Revolution for the PlayStation 4 . \n",
      "\n",
      " \n",
      "\n",
      " = = Gameplay = = \n",
      "\n",
      " \n",
      "\n",
      " As with previous <unk> Chronicles games , Valkyria Chronicles III is a tactical role @-@ playing game where players take control of a military unit and take part in missions against enemy forces . Stories are told through comic book @-@ like panels with animated character portraits , with characters speaking partially through voiced speech bubbles and partially through <unk> text . The player progresses through a series of linear missions , gradually unlocked as maps that can be freely <unk> through and replayed as they are unlocked . The route to each story location on the map varies depending on an individual player 's approach : when one option is selected , the other is sealed off to the player . Outside missions , the player characters rest in a camp , where units can be customized and character growth occurs . Alongside the main story missions are character @-@ specific sub missions relating to different squad members . After the game 's completion , additional episodes are unlocked , some of them having a higher difficulty than those found in the rest of the game . There are also love simulation elements related to the game 's two main <unk> , although they take a very minor role . \n",
      "\n"
     ]
    }
   ],
   "source": [
    "path_train = '/opt/ml/RNN_homework/train.txt'\n",
    "with open(path_train, 'r', encoding=\"utf8\") as f:\n",
    "    corpus_train = f.readlines()    \n",
    "\n",
    "# train dataset 크기 확인\n",
    "print(len(corpus_train))\n",
    "\n",
    "# 처음 10 문장을 print 해 봅시다.\n",
    "for sent in corpus_train[:10]:\n",
    "    print(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_xzSMF9RJyzg"
   },
   "source": [
    "### 1. 서브워드 토큰화의 필요성\n",
    "\n",
    "💡 서브워드(Subword)는 무엇인가요?\n",
    "\n",
    "서브워드는 하나의 단어를 여러개의 단위로 분리했을 때 하나의 단위를 나타냅니다. `subword`를 서브워드 단위로 나타낸 하나의 예시는 다음과 같습니다.\n",
    "\n",
    " * `sub` + `word`\n",
    "\n",
    "`sub`라는 접두사와 `word`라고 하는 어근으로 나누어 `subword`라고 하는 단어를 2개의 서브 워드로 나타냈습니다.\n",
    "\n",
    "이외에도 다양한 형태의 서브워드로 나타낼 수 있습니다. (e.g., `su` + `bword`, `s` + `ubword`, `subwor` + `d`)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BVQgjQJdAbWh"
   },
   "source": [
    "💡 그럼 서브워드 토큰화(Subword tokenization)는 무엇인가요?\n",
    "\n",
    "서브워드 토큰화는 말 그대로 서브워드 단위로 토큰화를 한다는 뜻입니다.\n",
    "기본 과제 1에서 나온 단어단위 토큰화를 적용한 뒤, 서브워드 토큰화를 수행한 예시를 보겠습니다.\n",
    "\n",
    "서브워드 토큰화를 적용했을 때는 다음과 같이 토큰화할 수 있습니다.\n",
    "\n",
    "* Example 1\n",
    "> \"I have a meal\" -> ['I', 'hav', 'e', 'a', 'me', 'al']\n",
    ">\n",
    "> \"나는 밥을 먹는다\" -> ['나', '는', '밥', '을', '먹는', '다']\n",
    "\n",
    "단어단위가 아니라 그보다 더 잘게 쪼갠 서브워드 단위로 문장을 토큰화합니다.\n",
    "\n",
    "위에서 말씀드린 것과 같이 여러가지 경우의 수가 가능합니다.\n",
    "\n",
    "* Example 2\n",
    "> \"I have a meal\" -> ['I', 'ha', 've', 'a', 'mea', 'l']\n",
    ">\n",
    "> \"나는 밥을 먹는다\" -> ['나', '는', '밥', '을', '먹', '는다']\n",
    "\n",
    "그렇지만 기본적으로 공백을 넘어선 서브를 구성하진 않습니다.\n",
    "예를 들어 다음과 같이 토큰화를 수행하진 않습니다.\n",
    "\n",
    "* Example 3\n",
    "> \"I have a meal\" -> ['Iha', 've', 'am', 'ea', 'l']\n",
    ">\n",
    "> \"나는 밥을 먹는다\" -> ['나는밥', '을먹', '는다']\n",
    "\n",
    "(참고4: [Huggingface: subword-tokenization](https://huggingface.co/transformers/tokenizer_summary.html#subword-tokenization))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SPRNaFhMEK67"
   },
   "source": [
    "💡 Subword tokenization은 왜 필요한가요?\n",
    "\n",
    "첫 번째 이유는 이 세상에 단어가 너무 많기 때문입니다.\n",
    "이전 과제에서 사용했던 코드를 불러와 그 필요성을 생각해 봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "id": "SWd09aUBGWa9"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "class Dictionary(object):\n",
    "    def __init__(self):\n",
    "        self.token2id = {}\n",
    "        self.id2token = []\n",
    "\n",
    "    def add_word(self, word):\n",
    "        if word not in self.token2id:\n",
    "            self.id2token.append(word)\n",
    "            self.token2id[word] = len(self.id2token) - 1\n",
    "        return self.token2id[word]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.id2token)\n",
    "\n",
    "class Corpus(object):\n",
    "    def __init__(self, path):\n",
    "        self.dictionary = Dictionary()\n",
    "        self.train = self.tokenize(os.path.join(path, 'train.txt'))\n",
    "        self.valid = self.tokenize(os.path.join(path, 'valid.txt'))\n",
    "        self.test = self.tokenize(os.path.join(path, 'test.txt'))\n",
    "\n",
    "    def tokenize(self, path):\n",
    "        \"\"\"Tokenizes a text file.\"\"\"\n",
    "        assert os.path.exists(path)\n",
    "        # Add words to the dictionary\n",
    "        with open(path, 'r', encoding=\"utf-8\") as f:\n",
    "            for line in f:\n",
    "                words = line.split() + ['<eos>']\n",
    "                for word in words:\n",
    "                    self.dictionary.add_word(word)\n",
    "\n",
    "        # Tokenize file content\n",
    "        with open(path, 'r', encoding=\"utf-8\") as f:\n",
    "            idss = []\n",
    "            for line in f:\n",
    "                words = line.split() + ['<eos>']\n",
    "                ids = []\n",
    "                for word in words:\n",
    "                    ids.append(self.dictionary.token2id[word])\n",
    "                idss.append(torch.tensor(ids).type(torch.int64))\n",
    "            ids = torch.cat(idss)\n",
    "\n",
    "        return ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "id": "FLT1GR2To41u"
   },
   "outputs": [],
   "source": [
    "from typing import Union, Tuple\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, \n",
    "        rnn_type: str,\n",
    "        vocab_size: int,\n",
    "        embedding_size: int=200,\n",
    "        hidden_size: int=200,\n",
    "        num_hidden_layers: int=2,\n",
    "        dropout: float=0.5\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.rnn_type = rnn_type\n",
    "        self.vocab_size = vocab_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_hidden_layer = num_hidden_layers\n",
    "        assert rnn_type in {'LSTM', 'GRU', 'RNN_TANH', 'RNN_RELU'}\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_size)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        if rnn_type.startswith('RNN'):\n",
    "            nonlinearity = rnn_type.split('_')[-1].lower()\n",
    "            self.rnn = nn.RNN(\n",
    "                embedding_size, \n",
    "                hidden_size, \n",
    "                num_hidden_layers,\n",
    "                batch_first=True, \n",
    "                nonlinearity=nonlinearity,\n",
    "                dropout=dropout\n",
    "            )\n",
    "        else:\n",
    "            self.rnn = getattr(nn, rnn_type)(\n",
    "                embedding_size,\n",
    "                hidden_size,\n",
    "                num_hidden_layers,\n",
    "                batch_first=True,\n",
    "                dropout=dropout\n",
    "            )\n",
    "\n",
    "        self.projection = nn.Linear(hidden_size, vocab_size)\n",
    "\n",
    "    def forward(\n",
    "        self, \n",
    "        input: torch.Tensor,\n",
    "        prev_hidden: Union[torch.Tensor, Tuple[torch.Tensor, torch.Tensor]]\n",
    "    ):\n",
    "        \"\"\" RNN 모델의 forward 함수 구현\n",
    "        위의 그림과 __init__ 함수 내 주석을 참고하여 forward 함수를 구현하세요.\n",
    "\n",
    "        Hint 2: RNN 모델에선 Dropout을 곳곳에 적용하는 것이 성능이 좋다고 알려져 있습니다.\n",
    "                예를 들어, Embedding 이후와 Projection 전에도 적용할 수 있습니다.\n",
    "        Hint 2: 최종 확률값을 구하기 위해서 Projection 이후에 F.log_softmax를 사용하면 됩니다.\n",
    "\n",
    "        Arguments:\n",
    "        input -- 토큰화 및 배치화된 문장들의 텐서\n",
    "                    dtype: torch.long\n",
    "                    shape: [batch_size, sequence_lentgh]\n",
    "        prev_hidden -- 이전의 hidden state\n",
    "                    dtype: torch.float\n",
    "                    shape: RNN, GRU - [num_layers, batch_size, hidden_size]\n",
    "                           LSTM - ([num_layers, batch_size, hidden_size], [num_layers, batch_size, hidden_size])\n",
    "\n",
    "        Return:\n",
    "        log_prob -- 다음 토큰을 예측한 확률에 log를 취한 값\n",
    "                    dtype: torch.float\n",
    "                    shape: [batch_size, sequence_length, vocab_size]\n",
    "        next_hidden -- 이후의 hidden state\n",
    "                    dtype: torch.float\n",
    "                    shape: RNN, GRU - [num_layers, batch_size, hidden_size]\n",
    "                           LSTM - ([num_layers, batch_size, hidden_size], [num_layers, batch_size, hidden_size])\n",
    "        \"\"\"\n",
    "        ### YOUR CODE HERE\n",
    "        ### ANSWER HERE ###\n",
    "        emb = self.dropout(self.embedding(input))\n",
    "        output, next_hidden = self.rnn(emb, prev_hidden)\n",
    "        log_prob = self.projection(self.dropout(output)).log_softmax(dim=-1)\n",
    "\n",
    "        ### END YOUR CODE\n",
    "        \n",
    "        assert list(log_prob.shape) == list(input.shape) + [self.vocab_size]\n",
    "        assert prev_hidden.shape == next_hidden if self.rnn_type != 'LSTM' \\\n",
    "          else prev_hidden[0].shape == next_hidden[0].shape == next_hidden[1].shape\n",
    "        \n",
    "        return log_prob, next_hidden\n",
    "    \n",
    "    def init_hidden(self, batch_size: int):\n",
    "        \"\"\" 첫 hidden state를 반환하는 함수 \"\"\"\n",
    "        \n",
    "        weight = self.projection.weight\n",
    "        \n",
    "        if self.rnn_type == 'LSTM':\n",
    "            return (weight.new_zeros(self.num_hidden_layer, batch_size, self.hidden_size),\n",
    "                    weight.new_zeros(self.num_hidden_layer, batch_size, self.hidden_size))\n",
    "        else:\n",
    "            return weight.new_zeros(self.num_hidden_layer, batch_size, self.hidden_size)\n",
    "    \n",
    "    @property\n",
    "    def device(self):   # 현재 모델의 device를 반환하는 프로퍼티\n",
    "        return self.projection.weight.device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xnsZkQqUHb6Z"
   },
   "source": [
    "말뭉치의 문장들을 단어단위 토큰화를 해보고 단어들의 개수를 세어보겠습니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2aSB9Hk4HjyO",
    "outputId": "f7e2a79f-c13d-483e-b518-e532067ba8c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33278\n"
     ]
    }
   ],
   "source": [
    "corpus = Corpus('/opt/ml/RNN_homework/')\n",
    "vocab_size = len(corpus.dictionary)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OBkvRpEcKEvd"
   },
   "source": [
    "이전 과제에 사용된 임베딩의 크기는 200이므로 단어 임베딩에 사용된 매개변수의 수는 33278 x 200 (6,655,600개)입니다.\n",
    "그렇다면, RNN 모델에 사용되는 weight의 parameter 개수는 몇개인지 간단한 함수를 이용해 확인해보겠습니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "id": "rGjG2j-fKbJu"
   },
   "outputs": [],
   "source": [
    "model = RNNModel('RNN_TANH', vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yTiKccVXLrvx",
    "outputId": "d45f322e-9f5b-45eb-ad52-c9b408f617eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word embedding parameter 개수: 6655600\n",
      "RNN parameter 개수: 160800\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"Word embedding parameter 개수: {count_parameters(model.embedding)}\")\n",
    "print(f\"RNN parameter 개수: {count_parameters(model.rnn)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nlUFvgTNM1Od"
   },
   "source": [
    "💡 RNN 층의 매개변수 개수와, 임베딩 매개변수 개수를 비교해보면 임베딩 매개변수의 개수가 RNN층의 매개변수 수보다 압도적으로 많습니다.\n",
    "\n",
    "단어단위 임베딩을 사용하는 경우 학습에 사용되는 말뭉치의 크기가 커질수록 등장하는 단어가 더더욱 많아져 임베딩의 매개변수는 더 커지게 되고 전체 매개변수 대비 단어 임베딩이 차지하는 비중은 매우 높아집니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o7WfyYBrPpca"
   },
   "source": [
    "✨ 이런 매개변수 비중의 비대칭성을 해결하기 위해 처음에는 문자단위 토큰화(character-level tokenization) 방법이 주목을 받았습니다. \n",
    "말 그대로 하나의 글자를 기준으로 토큰화을 하는건데요.\n",
    "이전 예시를 문자단위 토큰화를 하면 다음과 같습니다.\n",
    "\n",
    "\"I have a meal\" -> ['I', 'h', 'a', 'v', 'e', 'a', 'm', 'e', 'a', 'l']\n",
    "\"나는 밥을 먹는다\" -> ['나', '는', '밥', '을', '먹', '는', '다']\n",
    "\n",
    "그러나, 문자단위 토큰화 역시 지나치게 긴 Sequence 길이, 성능 저하 등의 문제를 겪으며 서브워드 토큰화가 각광을 받게 되었습니다.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZBI03OI1o41w"
   },
   "source": [
    "💡서브워드 토큰화가 가지는 두번째 장점은 Out-of-Vocabulary (OoV) 문제가 없다는 점입니다.\n",
    "\n",
    "학습 데이터에서 등장하지 않은 단어는 모두 Unknown 토큰 [UNK]로 처리됩니다. 이는 테스트 과정 중에 처음 보는 단어를 모두 [UNK]로 모델의 입력을 넣게 되면서 전체적으로 모델의 성능이 저하될 수 있습니다.\n",
    "\n",
    "그러나 서브워드 단위로 자르게 된다면 최악의 경우에도 문자단위로 토큰화가 진행됩니다. 이는 서브워드 토큰화는 현재 가지고 있는 Vocab으로 해당 단어가 토큰화할 수 없다면 그 단어를 서브워드 단위로 쪼개 평가하기 때문입니다.\n",
    "\n",
    "따라서 서브워드 토큰화기는 가장 작은 문자 단위로 서브워드 토큰화가 가능하기 때문에 OoV 문제가 발생하지 않습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jVbjVR3Io41w"
   },
   "source": [
    "### 2. Byte Pair Encoding (BPE)\n",
    "> 이 섹터에서는 파이썬 표준 라이브러리 (Python Standard Library)만 사용하세요.\n",
    "\n",
    "대표적인 서브워드 토큰화 방법인 Byte pair encoding을 구현해봅시다. BPE의 정확한 알고리즘은 [논문](https://arxiv.org/pdf/1508.07909.pdf)의 3페이지 algorithm 1에 제시되어 있습니다. 각 문항과 주석의 지시사항을 확인하고 BPE를 구현해보세요.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K73a8sreo41x"
   },
   "source": [
    "### 2-A) BPE Vocab 만들기\n",
    "\n",
    "BPE의 Vocab을 만드는 것은 간단합니다. 단순히 가장 많이 등장하는 연속한 짝을 찾아 추가하는 것 입니다.\n",
    "다음과 같은 말뭉치가 있다고 가정해 봅시다.\n",
    "\n",
    "```\n",
    "low lower lowest newest\n",
    "```\n",
    "\n",
    "우선은 공백을 제외한 모든 문자를 Vocab에 추가하고 각 단어의 끝에 WORD_END \"`_`\" 붙여 단어를 구분지어 봅시다.\n",
    "\n",
    "```\n",
    "Vocab: d e i l n o r s t w _\n",
    "[ l o w _ ], [ l o w e r _ ], [ l o w e s t _ ], [ w i d e s t _ ]  \n",
    "```\n",
    "\n",
    "이때 가장 많이 등장한 연속한 두 토큰을 찾아 Vocab에 추가하고 두 토큰을 붙입니다. 이 경우에는 `l o`가 세번 등장하여 가장 많았으니 `lo`로 붙여 Vocab에 추가합니다.\n",
    "\n",
    "```\n",
    "Vocab: d e i l n o r s t w _ lo\n",
    "[ lo w _ ], [ lo w e r _ ], [ lo w e s t _ ], [ w i d e s t _ ] \n",
    "```\n",
    "\n",
    "다음은 `lo w`가 세번 등장하므로 `low`를 추가합니다.\n",
    "\n",
    "```\n",
    "Vocab: d e i l n o r s t w _ lo low\n",
    "[ low _ ], [ low e r _ ], [ low e s t _ ], [ w i d e s t _ ] \n",
    "```\n",
    "\n",
    "다음은 `e s`가 두번 등장하므로 `es`를 추가합니다.\n",
    "\n",
    "```\n",
    "Vocab: d e i l n o r s t w _ lo low es\n",
    "[ low _ ], [ low e r _ ], [ low es t _ ], [ w i d es t _ ] \n",
    "```\n",
    "\n",
    "다음은 `es t`가 두번 등장하므로 `est`를 추가합니다.\n",
    "\n",
    "```\n",
    "Vocab: d e i l n o r s t w _ lo low es est\n",
    "[ low _ ], [ low e r _ ], [ low est _ ], [ w i d est _ ] \n",
    "```\n",
    "\n",
    "다음은 `est _`가 두번 등장하므로 `est_`를 추가합니다.\n",
    "\n",
    "```\n",
    "Vocab: d e i l n o r s t w _ lo low es est est_\n",
    "[ low _ ], [ low e r _ ], [ low est_ ], [ w i d est_ ] \n",
    "```\n",
    "\n",
    "`est_`는 est로 단어가 끝난다는 것을 알려주는 서브워드가 됩니다. 일반적으로 est가 나오면 단어가 끝나니 합리적입니다.\n",
    "\n",
    "이러한 과정을 통해서 모든 단어가 추가되거나 원하는 Vocab 크기에 도달할 때까지 서브워드를 통합하여 추가하는 과정을 반복하면 됩니다. 알고리즘을 참고하여 `build_bpe`를 작성해 봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "id": "No6tMv2co41x"
   },
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import collections, re\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 단어 끝을 나타내는 문자\n",
    "WORD_END = '_'\n",
    "\n",
    "def build_bpe(\n",
    "    corpus: List[str],\n",
    "    max_vocab_size: int\n",
    ") -> List[int]:\n",
    "    \"\"\" BPE Vocab 만들기\n",
    "    Byte Pair Encoding을 통한 Vocab 생성을 구현하세요.\n",
    "    단어의 끝은 '_'를 사용해 주세요.\n",
    "    이때 id2token을 서브워드가 긴 길이 순으로 정렬해 주세요.\n",
    "    \n",
    "    Note: 만약 모든 단어에 대해 BPE 알고리즘을 돌리게 되면 매우 비효율적입니다.\n",
    "          왜냐하면 대부분의 단어는 중복되기 때문에 중복되는 단어에 대해서는 한번만 연산할 수 있다면 매우 효율적이기 때문입니다.\n",
    "          따라서 collections 라이브러리의 Counter를 활용해 각 단어의 빈도를 구하고,\n",
    "          각 단어에 빈도를 가중치로 활용하여 BPE를 돌리면 시간을 획기적으로 줄일 수 있습니다.\n",
    "          물론 이는 Optional한 요소입니다.\n",
    "\n",
    "    Arguments:\n",
    "    corpus -- Vocab을 만들기 위한 단어 리스트\n",
    "    max_vocab_size -- 최대 vocab 크기\n",
    "\n",
    "    Return:\n",
    "    id2token -- 서브워드 Vocab. 문자열 리스트 형태로 id로 token을 찾는 매핑으로도 활용 가능\n",
    "    \"\"\"\n",
    "    ### YOUR CODE HERE\n",
    "    def get_stats(vocab):\n",
    "        pairs=collections.defaultdict(int)\n",
    "        for word,freq in vocab.items():\n",
    "            word=word.split(' ')\n",
    "            for i in range(len(word)-1):\n",
    "                pairs[word[i]+word[i+1]] +=freq\n",
    "\n",
    "        return pairs\n",
    "\n",
    "    def merge_vocab(vocab,pair):\n",
    "        v_out={}\n",
    "        for word,freq in vocab.items():\n",
    "            word_list=word.split(' ')\n",
    "            for i in range(len(word_list)-1):\n",
    "                if pair == word_list[i]+word_list[i+1]:\n",
    "                    sub=word_list[i]+' '+word_list[i+1]\n",
    "                    word= word.replace(sub,pair)\n",
    "                    break\n",
    "            \n",
    "            if word not in v_out:\n",
    "                v_out[word]=freq\n",
    "            else:\n",
    "                v_out[word]+= freq\n",
    "\n",
    "        return v_out\n",
    "    \n",
    "    corpus= Counter(corpus)\n",
    "    vocab={}\n",
    "    \n",
    "    for word, freq in corpus.items():\n",
    "        s=''\n",
    "        for letter in word:\n",
    "            s+=letter\n",
    "            s+=' '\n",
    "        s+=('_')\n",
    "        vocab[s] = freq\n",
    "        \n",
    "      \n",
    "    id2token=[]\n",
    "    id2token.append('_')\n",
    "    for word in set(corpus):\n",
    "        for letter in word:\n",
    "            if letter not in id2token and letter != ' ':\n",
    "                id2token.append(letter)    \n",
    "    while len(id2token) < max_vocab_size:\n",
    "        pairs= get_stats(vocab)\n",
    "        if len(pairs) ==0 :\n",
    "            break\n",
    "        if len(pairs) ==1 :\n",
    "            best=list(pairs.keys())[0]\n",
    "        else:\n",
    "            \n",
    "            best=max(pairs, key= pairs.get)        \n",
    "        vocab=merge_vocab(vocab,best)\n",
    "        if best not in id2token:\n",
    "            id2token.append(best)\n",
    "\n",
    "    \n",
    "\n",
    "    ### ANSWER HERE ###\n",
    "\n",
    "    ### END YOUR CODE\n",
    "    id2token = sorted(id2token,key=len, reverse=True)\n",
    "    \n",
    "    \n",
    "    \n",
    "    return id2token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t0BjnNpgo41x"
   },
   "source": [
    "**2-A 문제에 대한 테스트 코드**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 418
    },
    "id": "zKMn_ivmo41x",
    "outputId": "32433222-308d-4700-f0c8-4863b3ecad75"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======Building BPE Vocab Test Case======\n",
      "첫번째 테스트 통과!\n",
      "두번째 테스트 통과!\n",
      "세번째 테스트 통과!\n",
      "네번째 테스트 통과!\n",
      "모든 테스트 통과!\n"
     ]
    }
   ],
   "source": [
    "print (\"======Building BPE Vocab Test Case======\")\n",
    "\n",
    "# 첫번째 테스트\n",
    "corpus = ['abcde']\n",
    "vocab = build_bpe(corpus, max_vocab_size=15)\n",
    "assert sorted(vocab, key=len, reverse=True) == vocab, \\\n",
    "       \"id2token을 서브워드 길이가 긴 순으로 정렬해 주세요.\"\n",
    "print(\"첫번째 테스트 통과!\")\n",
    "\n",
    "# 두번째 테스트\n",
    "corpus = ['low'] * 5 + ['lower'] * 2 + ['newest'] * 6 + ['widest'] * 3\n",
    "vocab = set(build_bpe(corpus, max_vocab_size=19))\n",
    "assert vocab > {'est_', 'low', 'newest_', \\\n",
    "              'i', 'e', 'n', 't', 'd', 's', 'o', 'l', 'r', 'w', WORD_END} and \\\n",
    "       \"low_\" not in vocab and \"wi\" not in vocab and \"id\" not in vocab, \\\n",
    "       \"BPE 결과가 기대한 결과와 다릅니다.\"\n",
    "print(\"두번째 테스트 통과!\")\n",
    "\n",
    "# 세번째 테스트\n",
    "corpus = ['aaaaaaaaaaaa', 'abababab']\n",
    "vocab = set(build_bpe(corpus, max_vocab_size=8))\n",
    "assert vocab == {'aaaaaaaa', 'aaaa', 'abab', 'aa', 'ab', 'a', 'b', WORD_END}, \\\n",
    "       \"BPE 결과가 기대한 결과와 다릅니다.\"\n",
    "print(\"세번째 테스트 통과!\")\n",
    "\n",
    "# 네번째 테스트\n",
    "corpus = ['abc', 'bcd']\n",
    "vocab = build_bpe(corpus, max_vocab_size=10000)\n",
    "assert len(vocab) == 10, \\\n",
    "       \"BPE 결과가 기대한 결과와 다릅니다.\"\n",
    "print(\"네번째 테스트 통과!\")\n",
    "\n",
    "print(\"모든 테스트 통과!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kd9wdWpgo41y"
   },
   "source": [
    "### 2-B) BPE 인코딩\n",
    "만들어진 Vocab으로 텍스트 인코딩하는 방법은 몇 가지가 있습니다. 가장 쉬운 방법은 앞에서부터 토큰화하되 가장 긴 것부터 욕심쟁이 기법(Greedy Search)으로 먼저 매칭하는 방법입니다.\n",
    "\n",
    "```\n",
    "Vocab: bcde ab cd bc de a b c d e _\n",
    "abcde ==> ab cd e _\n",
    "```\n",
    "\n",
    "이 방법은 최적의 인코딩을 보장하진 않지만 긴 단어를 빠르게 인코딩하는 것이 가능합니다.\n",
    "\n",
    "두번째 방법은 가장 길게 매칭되는 것을 전체 텍스트에 대해 먼저 토큰화하는 방법입니다.\n",
    "\n",
    "```\n",
    "Vocab: bcde ab cd bc de a b c d e _\n",
    "abcde ==> a bcde _\n",
    "```\n",
    "\n",
    "두번째 방법은 첫번째 방법보다 느리지만 텍스트를 좀 더 짧게 인코딩하는 것이 가능합니다.\n",
    "\n",
    "이 과제에서는 두번째 방법을 이용하여 BPE 인코딩을 구현해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "id": "uLHKx2Qho41y"
   },
   "outputs": [],
   "source": [
    "def encode(\n",
    "    sentence: str,\n",
    "    id2token: List[str]\n",
    ") -> List[int]:\n",
    "    \"\"\" BPE 인코더\n",
    "    문장을 받아 BPE 토큰화를 통하여 고유 id의 수열로 바꿉니다.\n",
    "    문장은 공백으로 단어단위 토큰화되어있다고 가정하며, Vocab은 sentence의 모든 문자를 포함한다고 가정합니다.\n",
    "    찾을 수 있는 가장 긴 토큰부터 바꿉니다.\n",
    "    \n",
    "    Note: WORD_END를 빼먹지 마세요.\n",
    "\n",
    "    Arguments:\n",
    "    sentence -- 인코드하고자 하는 문장\n",
    "    id2token -- build_bpe를 통해 만들어진 Vocab\n",
    "    \n",
    "    Return:\n",
    "    token_ids -- 인코드된 토큰 id 수열\n",
    "    \"\"\"\n",
    "    token_ids=[]\n",
    "    sentences=sentence.split(' ')\n",
    "    for sentence in sentences:\n",
    "        sentence+='_'\n",
    "        for token in vocab:\n",
    "            if token in sentence:\n",
    "                sentence= sentence.replace(token,str(vocab.index(token)))\n",
    "        token_ids+=sentence\n",
    "        \n",
    "        \n",
    "\n",
    "    ### YOUR CODE HERE\n",
    "    ### ANSWER HERE ###\n",
    "\n",
    "    ### END YOUR CODE\n",
    "    for i in range(len(token_ids)):\n",
    "        token_ids[i] = int(token_ids[i])\n",
    "    return token_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f7cHzDETo41y"
   },
   "source": [
    "**2-B 문제에 대한 테스트 코드**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "id": "lQOt8lz4o41y"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======Encoding Test Case======\n",
      "첫번째 테스트 통과!\n",
      "두번째 테스트 통과!\n",
      "모든 테스트 통과!\n"
     ]
    }
   ],
   "source": [
    "print (\"======Encoding Test Case======\")\n",
    "\n",
    "# 첫번째 테스트\n",
    "vocab = ['bcc', 'bb', 'bc', 'a', 'b', 'c', WORD_END]\n",
    "assert encode('abbccc', vocab) == [3, 4, 0, 5, 6], \\\n",
    "       \"BPE 인코딩 결과가 기대한 결과와 다릅니다.\"\n",
    "print(\"첫번째 테스트 통과!\")\n",
    "\n",
    "# Second test\n",
    "vocab = ['aaaa', 'aa', 'a', WORD_END]\n",
    "assert len(encode('aaaaaaaa aaaaaaa', vocab)) == 7, \\\n",
    "       \"BPE 인코딩 결과가 기대한 결과와 다릅니다.\"\n",
    "print(\"두번째 테스트 통과!\")\n",
    "\n",
    "print(\"모든 테스트 통과!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1CGfMVhVo41y"
   },
   "source": [
    "### 2-C) BPE 디코딩"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cG8QmbaLo41y"
   },
   "source": [
    "BPE로 인코딩된 것을 디코딩하는 것은 간단합니다.\n",
    "그저 해당 id를 해당하는 서브워드로 만든 뒤 합치면됩니다.\n",
    "WORD_END는 공백으로 처리하면 쉽습니다.\n",
    "\n",
    "```\n",
    "[ 196 62 20 6 ] ==> [ I_ li ke_ it_ ] ==> \"I_like_it_\" ==> \"I like it \" ==> \"I like it\"  \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "id": "9stE7H6lo41z"
   },
   "outputs": [],
   "source": [
    "def decode(\n",
    "    token_ids: List[int],\n",
    "    id2token: List[str]\n",
    ") -> str:\n",
    "    \"\"\" BPE 디코더\n",
    "    BPE로 토큰화된 id 수열을 받아 문장으로 바꿉니다.\n",
    "    단어단위 토큰화에서의 문장 복원은 단순히 공백을 사이에 넣는 디코딩을 사용합니다.\n",
    "    문장 끝의 공백은 잘라냅니다.\n",
    "    \n",
    "    Arguments:\n",
    "    token_ids -- 디코드하고자하는 토큰 id 수열\n",
    "    id2token -- build_bpe를 통해 만들어진 Vocab\n",
    "\n",
    "    Return:\n",
    "    sentence  -- 디코드된 문장\n",
    "    \"\"\"\n",
    "\n",
    "    ### YOUR CODE HERE\n",
    "    ### ANSWER HERE ###\n",
    "    sentence=''\n",
    "    for ids in token_ids:\n",
    "        sentence+=id2token[ids]\n",
    "    \n",
    "    sentences=sentence.replace('_',' ')\n",
    "    \n",
    "    sentences = sentences[:-1]\n",
    "    ### END YOUR CODE\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IAJKJzdMo41z"
   },
   "source": [
    "**2-C 문제에 대한 테스트 코드**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "id": "XXC9vdLwo41z"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======Decoding Test Case======\n",
      "첫번째 테스트 통과!\n",
      "두번째 테스트 통과!\n"
     ]
    }
   ],
   "source": [
    "print (\"======Decoding Test Case======\")\n",
    "# First test\n",
    "vocab = ['bcc', 'bb', 'bc', 'a', 'b', 'c', WORD_END]\n",
    "assert decode([3, 4, 0, 5, 6], vocab) == 'abbccc', \\\n",
    "           \"BPE 디코딩 결과가 기대한 결과와 다릅니다.\"\n",
    "print(\"첫번째 테스트 통과!\")\n",
    "\n",
    "# Second test\n",
    "vocab = ['aaaa', 'aa', 'a', WORD_END]\n",
    "assert decode([0, 0, 3, 0, 1, 2, 3], vocab) == 'aaaaaaaa aaaaaaa', \\\n",
    "           \"BPE 디코딩 결과가 기대한 결과와 다릅니다.\"\n",
    "print(\"두번째 테스트 통과!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iNXD4Ml_RVGb"
   },
   "source": [
    "### 3. Transformers 라이브러리를 활용한 서브워드 토큰화\n",
    "\n",
    "✨ 위에서 작성한 BPE 구현체를 통해 서브워드 토큰화의 원리를 알 수 있지만, 위의 구현체를 실제로 사용하기에는 난점이 존재합니다.\n",
    "왜냐하면 BPE Vocab을 만드는 과정은 매우 오랜 시간이 걸리기 때문입니다.\n",
    "다양한 토큰화기(tokenizer)를 직접 구현하고 학습하는 것은 매우 비용이 크기 때문에, 라이브러리를 활용하여 토큰화기를 사용하는 방법을 알아봅시다.\n",
    "\n",
    "[Transformer](https://huggingface.co/docs/transformers/index) 라이브러리는 다양한 Transformer 구현체를 총망라한 라이브러리입니다.\n",
    "Transfomer 외에도 다양한 토큰화기를 지원하는데, 이미 학습된 서브워드 토큰화기 역시 쉽게 불러올 수 있습니다.\n",
    "\n",
    "(참고5: [Huggingface: subword tokenization](https://huggingface.co/transformers/tokenizer_summary.html#subword-tokenization))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "id": "vEfuauieo41z"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.8/site-packages (4.17.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.8/site-packages (from transformers) (4.51.0)\n",
      "Requirement already satisfied: sacremoses in /opt/conda/lib/python3.8/site-packages (from transformers) (0.0.47)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /opt/conda/lib/python3.8/site-packages (from transformers) (0.4.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.8/site-packages (from transformers) (2.24.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.8/site-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.8/site-packages (from transformers) (21.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.8/site-packages (from transformers) (5.3.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,>=0.11.1 in /opt/conda/lib/python3.8/site-packages (from transformers) (0.11.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.8/site-packages (from transformers) (2022.3.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.8/site-packages (from transformers) (1.19.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.7.4.3)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging>=20.0->transformers) (2.4.7)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.8/site-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests->transformers) (1.25.11)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests->transformers) (2020.12.5)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.8/site-packages (from sacremoses->transformers) (1.0.1)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.8/site-packages (from sacremoses->transformers) (1.15.0)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.8/site-packages (from sacremoses->transformers) (8.0.4)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: You are using pip version 22.0.3; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the '/opt/conda/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "id": "WZKyn3PKUuBg"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizerFast\n",
    "\n",
    "# BERT 모델에서 사용하는 토큰화를 가져옵니다.\n",
    "# https://huggingface.co/docs/transformers/model_doc/bert#transformers.BertTokenizerFast\n",
    "tokenizer = BertTokenizerFast.from_pretrained(\n",
    "    \"bert-base-cased\",\n",
    "    unk_token='<unk>',\n",
    "    eos_token='<eos>'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4KCFLlSBo41z"
   },
   "source": [
    "**Question**\n",
    "\n",
    "Transformers에서 제공되는 BertTokenizerFast는 모든 조합을 만들 수 있는 서브워드 기반 토큰화기임에도 불구하고 위와 같이 Unknown 토큰을 받을 수 있다. 서브워드 토큰화기에서 Unknown 토큰이 발생할 수 있는 상황은 무엇이 있을까?\n",
    "\n",
    "**Answer**\n",
    "\n",
    "토큰이 vocabulary에 존재하지 않는경우 unk 토큰을 받는다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "id": "rwubp25xVUt2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Bo', '##ost', '##cam', '##p', 'AI', 'Tech']\n",
      "[9326, 15540, 24282, 1643, 19016, 7882]\n",
      "Boostcamp AI Tech\n",
      "['q', '##wer', '##k', '##l', '##h', '##fa', 'as', '##d', '##f', '##k', '##we', '##j', 'ads', '##fe', '##s', '##d', '##ff']\n",
      "[186, 12097, 1377, 1233, 1324, 8057, 1112, 1181, 2087, 1377, 7921, 3361]\n",
      "qwerklhfa asdfkwej\n"
     ]
    }
   ],
   "source": [
    "# 서브워드 토큰화 예시\n",
    "print(tokenizer.tokenize('Boostcamp AI Tech'))\n",
    "token_ids = tokenizer(\"Boostcamp AI Tech\", add_special_tokens=False).input_ids\n",
    "print(token_ids)\n",
    "print(tokenizer.decode(token_ids))\n",
    "\n",
    "print(tokenizer.tokenize('qwerklhfa asdfkwej \\n adsfesdff'))\n",
    "token_ids = tokenizer(\"qwerklhfa asdfkwej\", add_special_tokens=False).input_ids\n",
    "print(token_ids)\n",
    "print(tokenizer.decode(token_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BvtarB2DYiLb"
   },
   "source": [
    "이 토큰화기는 `##`을 통하여 현 단어가 이전 단어와 연결되어 있는지를 알려주고 있습니다. 이 토큰화기를 기반으로 다시 모델을 선언하고 parameter의 개수를 살펴보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "id": "wLKqis0hY5Or"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28998\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(tokenizer)\n",
    "print(vocab_size)\n",
    "subword_model = RNNModel('RNN_TANH', vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "id": "_RB4DQ-QZCBd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "임베딩 매개변수 개수: 5799600\n",
      "RNN층 매개변수 개수: 160800\n"
     ]
    }
   ],
   "source": [
    "print(f\"임베딩 매개변수 개수: {count_parameters(subword_model.embedding)}\")\n",
    "print(f\"RNN층 매개변수 개수: {count_parameters(subword_model.rnn)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q_5y4M6k1HR6"
   },
   "source": [
    "이전에 비해 임베딩 매개변수 개수는 확연히 줄어들었습니다.\n",
    "\n",
    "6,655,600개 -> 5,799,600개\n",
    "\n",
    "그에 비하여 이 토큰화기는 이전 토큰화기와 달리 학습 데이터에 없었던 영어 단어가 새로 나오더라도 토큰화가 가능합니다. \n",
    "\n",
    "그러면 이제 서브워드 토큰화 기반의 언어 모델 성능을 살펴봅시다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "md_oQZeso410"
   },
   "source": [
    "### 4. 서브워드 기반 Language Model 학습\n",
    "앞서 확인해본 `transformers` 라이브러리 기반 토큰화기를 활용하여 서브워드 기반 Lanuage Model을 학습시켜 봅시다. 기본 과제 2를 참고하여 구현해봅시다. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "id": "PX2amGs_o410"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (655 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batchifiy done\n",
      "batchifiy done\n",
      "batchifiy done\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2331f38060347e9a1da8f527e628370",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Train'), FloatProgress(value=0.0, max=2230.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "192fe17ae9e04035a63cb6657a1cd06d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Eval'), FloatProgress(value=0.0, max=222.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "| End of epoch  1 | valid loss  5.82 | valid ppl   336.81\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a07a90882b640448fd98dbd8639a48e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Train'), FloatProgress(value=0.0, max=2230.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e34cc3406cb4b72bdfb9e306102743a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Eval'), FloatProgress(value=0.0, max=222.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "| End of epoch  2 | valid loss  5.63 | valid ppl   278.17\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ca75d8330c342df9bebe400544ec940",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Train'), FloatProgress(value=0.0, max=2230.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd5837dc515340e598897ce85d0cb8f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Eval'), FloatProgress(value=0.0, max=222.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "| End of epoch  3 | valid loss  5.54 | valid ppl   254.64\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4fba4fb78f444d48deb6e3f84277714",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Train'), FloatProgress(value=0.0, max=2230.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8123b8e260de4dda944e53892cfdc649",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Eval'), FloatProgress(value=0.0, max=222.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "| End of epoch  4 | valid loss  5.44 | valid ppl   230.80\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ec54b9a1f5541e7bf5a1d33f5bbcdc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Train'), FloatProgress(value=0.0, max=2230.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7488741505a341faa0fae79c977e502c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Eval'), FloatProgress(value=0.0, max=222.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "| End of epoch  5 | valid loss  5.38 | valid ppl   217.46\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77340e13ba934ba3990d12b9274043b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Train'), FloatProgress(value=0.0, max=2230.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac0eaf837b65404781b15bae143a6c27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Eval'), FloatProgress(value=0.0, max=222.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "| End of epoch  6 | valid loss  5.32 | valid ppl   205.29\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "387b75eafb5f45eeaa149d8d82d06622",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Train'), FloatProgress(value=0.0, max=2230.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a0df01edd014241b8a1ac0ee92d8bd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Eval'), FloatProgress(value=0.0, max=222.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "| End of epoch  7 | valid loss  5.30 | valid ppl   200.82\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d344ea0c03b4ea5853e0a0a7861552b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Train'), FloatProgress(value=0.0, max=2230.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "187afafccd844bfcb81e27268a560f3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Eval'), FloatProgress(value=0.0, max=222.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "| End of epoch  8 | valid loss  5.28 | valid ppl   195.88\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52827b9d8f7f46ee8a87b2cc85dcdef6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Train'), FloatProgress(value=0.0, max=2230.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9230f3c8a662458bad5df450f2b8d938",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Eval'), FloatProgress(value=0.0, max=222.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "| End of epoch  9 | valid loss  5.23 | valid ppl   186.21\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9953c1a6c0b4a28afe2212d1dc91ba1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Train'), FloatProgress(value=0.0, max=2230.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9752dfdfa3e7489a8bbf0034eb6301dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Eval'), FloatProgress(value=0.0, max=222.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "| End of epoch 10 | valid loss  5.21 | valid ppl   183.15\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "747583786fdd4c8fa75c4aef52199f64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Train'), FloatProgress(value=0.0, max=2230.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3393899141074fb399053cdd2bd5b842",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Eval'), FloatProgress(value=0.0, max=222.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "| End of epoch 11 | valid loss  5.18 | valid ppl   177.30\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "116cea4c91cb4d889a93708f108ef6e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Train'), FloatProgress(value=0.0, max=2230.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61c2ba75ae31469a8f9d33ef5b9a87f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Eval'), FloatProgress(value=0.0, max=222.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "| End of epoch 12 | valid loss  5.19 | valid ppl   180.02\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd3f30701a6a474fa097e57bd33c0c1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Train'), FloatProgress(value=0.0, max=2230.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "643ca4e8e80f4d45a1ca0e0dc0d9e35b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Eval'), FloatProgress(value=0.0, max=222.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "| End of epoch 13 | valid loss  5.09 | valid ppl   161.84\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30e1422da3b44c79b8ac52954f19ba30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Train'), FloatProgress(value=0.0, max=2230.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e70ba1762a5d4083b9fc6468c3a7a95f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Eval'), FloatProgress(value=0.0, max=222.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "| End of epoch 14 | valid loss  5.08 | valid ppl   161.21\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1529acb40ed84cda89d546fcce990d4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Train'), FloatProgress(value=0.0, max=2230.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17781aaf22a043c0a0d0dab9a2048273",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Eval'), FloatProgress(value=0.0, max=222.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "| End of epoch 15 | valid loss  5.07 | valid ppl   159.61\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "070bfbe6e15f4b1db2ca13d1e64ad7dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Train'), FloatProgress(value=0.0, max=2230.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "190b025bfdbf47fea382bdd446fd7948",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Eval'), FloatProgress(value=0.0, max=222.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "| End of epoch 16 | valid loss  5.06 | valid ppl   157.08\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8500508ace864c72a149380eeadee727",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Train'), FloatProgress(value=0.0, max=2230.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "828af12f4f8d42da8fb3590fe896f029",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Eval'), FloatProgress(value=0.0, max=222.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "| End of epoch 17 | valid loss  5.05 | valid ppl   156.70\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e9ded9399d74fe7a1d88b86a1a5ea5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Train'), FloatProgress(value=0.0, max=2230.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "131c9a5b6c85407a8c490318cd4203dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Eval'), FloatProgress(value=0.0, max=222.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "| End of epoch 18 | valid loss  5.05 | valid ppl   156.75\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f545ecb0c1842e38d701ff0e2a7235d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Train'), FloatProgress(value=0.0, max=2230.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1d879b281d44620880f16e0e27c5785",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Eval'), FloatProgress(value=0.0, max=222.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "| End of epoch 19 | valid loss  5.02 | valid ppl   151.49\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09b03bc79c1445af8d21e647286e2ff2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Train'), FloatProgress(value=0.0, max=2230.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f8d06b8f31d44859790bdb5a5b7d164",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Eval'), FloatProgress(value=0.0, max=222.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "| End of epoch 20 | valid loss  5.00 | valid ppl   149.10\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80a2066aaa7445429aae5ba73e67a9e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Train'), FloatProgress(value=0.0, max=2230.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e292c03ffc1a40c0847b7395d5a34e30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Eval'), FloatProgress(value=0.0, max=222.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "| End of epoch 21 | valid loss  5.00 | valid ppl   149.06\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d22c7b735e444893984cace50e8ebe7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Train'), FloatProgress(value=0.0, max=2230.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00c99c1002494625ab4039fad9f4c189",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Eval'), FloatProgress(value=0.0, max=222.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "| End of epoch 22 | valid loss  5.01 | valid ppl   149.25\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40df7d95ed244735a949c810a3c6a5db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Train'), FloatProgress(value=0.0, max=2230.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0310e5506ef41a18ee79b4130dc0de3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Eval'), FloatProgress(value=0.0, max=222.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "| End of epoch 23 | valid loss  4.98 | valid ppl   145.94\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f54db64542204dc5bd5c9737764f85d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Train'), FloatProgress(value=0.0, max=2230.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fef62f3a09a74e939c19532d50781c5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Eval'), FloatProgress(value=0.0, max=222.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "| End of epoch 24 | valid loss  4.98 | valid ppl   145.80\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b4bf1e2cd994ec983e5dce5404949e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Train'), FloatProgress(value=0.0, max=2230.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ce87aee431c4addb6f7f7e6f2a3a2a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Eval'), FloatProgress(value=0.0, max=222.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "| End of epoch 25 | valid loss  4.98 | valid ppl   145.30\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1abe0bc408264a25b275e9d7052a7262",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Train'), FloatProgress(value=0.0, max=2230.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fc4eb9a6fc64c97a6b4e72d62bea96c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Eval'), FloatProgress(value=0.0, max=222.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "| End of epoch 26 | valid loss  4.98 | valid ppl   145.20\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0afcc0bf9094daaa75b286d87502e2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Train'), FloatProgress(value=0.0, max=2230.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bfd9cf6335c47fbbe119b3ff99cae0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Eval'), FloatProgress(value=0.0, max=222.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "| End of epoch 27 | valid loss  4.98 | valid ppl   144.89\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a64881ace4894181865a34663a55932a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Train'), FloatProgress(value=0.0, max=2230.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f253dd688e9409abf24309fc0a1208f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Eval'), FloatProgress(value=0.0, max=222.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "| End of epoch 28 | valid loss  4.98 | valid ppl   144.96\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fe6964f855e49e782cc7e81200330da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Train'), FloatProgress(value=0.0, max=2230.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0f02b6a56cf4ec5a7415c566cda76a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Eval'), FloatProgress(value=0.0, max=222.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "| End of epoch 29 | valid loss  4.97 | valid ppl   143.74\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a16f2806dec48d3afcf25c402210ce7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Train'), FloatProgress(value=0.0, max=2230.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe0dc5e38638444da50bf7e2a91d98e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Eval'), FloatProgress(value=0.0, max=222.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "| End of epoch 30 | valid loss  4.97 | valid ppl   143.55\n",
      "-----------------------------------------------------------------------------------------\n",
      "Train done!!!!\n"
     ]
    }
   ],
   "source": [
    "### YOUR CODE HERE\n",
    "### 기본 과제 2를 참고해서 Language model 학습 코드를 작성해 보세요.\n",
    "### ANSWER HERE ###\n",
    "\n",
    "\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "from typing import Union,Tuple\n",
    "from transformers import BertTokenizerFast\n",
    "\n",
    "def bptt_batchify(data,batch_size,sequence_length):\n",
    "    \n",
    "    drop_data_len = len(data)%(batch_size*sequence_length)\n",
    "    data=data[:len(data)-drop_data_len]\n",
    "    data=torch.tensor(data)\n",
    "    data= data.view((batch_size,-1,sequence_length))\n",
    "    batches=np.transpose(data,(1,0,2))\n",
    "    \n",
    "    print('batchifiy done')\n",
    "    return batches\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "def train(model : RNNModel, data : torch.Tensor, lr:float):\n",
    "    model.train()\n",
    "    \n",
    "    batch_size = data.shape[1]\n",
    "    total_loss =0.\n",
    "    hidden = model.init_hidden(batch_size)\n",
    "    progress_bar = tqdm(data,desc=\"Train\")\n",
    "    for bid, batch in enumerate(progress_bar, start=1):\n",
    "        batch=batch.to(model.device)\n",
    "        output,hidden = model(batch,hidden)\n",
    "        if model.rnn_type == 'LSTM':\n",
    "            hidden = tuple(tensor.detach() for tensor in hidden)\n",
    "        else:\n",
    "            hidden = hidden.detach()\n",
    "        loss=F.nll_loss(output[:, :-1, :].transpose(1, 2), batch[:, 1:])\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        clip_grad_norm_(model.parameters(),0.25)\n",
    "        for param in model.parameters():\n",
    "            param.data.add_(param.grad,alpha=-lr)\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        current_loss = total_loss /bid\n",
    "        progress_bar.set_description(f\"Train - loss {current_loss:5.2f} | ppl {math.exp(current_loss):8.2f} | lr {lr:02.2f}\", refresh=False)\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model:RNNModel, data:torch.Tensor):\n",
    "    model.eval()\n",
    "    batch_size=data.shape[1]\n",
    "    total_loss=0\n",
    "    hidden=model.init_hidden(batch_size)\n",
    "    progress_bar = tqdm(data,desc='Eval')\n",
    "    for bid,batch in enumerate(progress_bar, start=1):\n",
    "        batch=batch.to(model.device)\n",
    "        output,hidden=model(batch,hidden)\n",
    "        if model.rnn_type == \"LSTM\":\n",
    "            hidden = tuple(tensor.detach() for tensor in hidden)\n",
    "        else:\n",
    "            hidden = hidden.detach()\n",
    "        \n",
    "        loss = F.nll_loss(output[:, :-1, :].transpose(1, 2), batch[:, 1:])\n",
    "        total_loss += loss.item()\n",
    "        current_loss = total_loss /bid\n",
    "        progress_bar.set_description(f\"Eval - loss {current_loss:5.2f} | ppl {math.exp(current_loss):8.2f}\", refresh=False)\n",
    "    \n",
    "    return loss\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "with open('/opt/ml/RNN_homework/train.txt', 'r', encoding=\"utf8\") as f:\n",
    "    corpus_train = f.readlines()   \n",
    "with open('/opt/ml/RNN_homework/valid.txt', 'r', encoding=\"utf8\") as f:\n",
    "    corpus_val = f.readlines()   \n",
    "with open('/opt/ml/RNN_homework/test.txt', 'r', encoding=\"utf8\") as f:\n",
    "    corpus_test = f.readlines()   \n",
    "    \n",
    "# BERT tokenizer ready\n",
    "tokenizer = BertTokenizerFast.from_pretrained(\n",
    "    \"bert-base-cased\",\n",
    "    unk_token='<unk>',\n",
    "    eos_token='<eos>'\n",
    ")\n",
    "\n",
    "#token to id\n",
    "train_token_ids = sum(tokenizer(corpus_train, add_special_tokens=False).input_ids,[])\n",
    "val_token_ids = sum(tokenizer(corpus_val, add_special_tokens=False).input_ids,[])\n",
    "test_token_ids =  sum(tokenizer(corpus_test, add_special_tokens=False).input_ids,[])\n",
    "#print(tokenizer.decode(token_ids))\n",
    "\n",
    "\n",
    "#datasets ready\n",
    "train_data = bptt_batchify(train_token_ids,batch_size=16,sequence_length=64)\n",
    "val_data = bptt_batchify(val_token_ids,batch_size=16,sequence_length=64)\n",
    "test_data = bptt_batchify(test_token_ids,batch_size=16,sequence_length=64)\n",
    "\n",
    "\n",
    "#model ready###################################\n",
    "vocab_size = len(tokenizer)\n",
    "model = RNNModel('LSTM', vocab_size)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model=model.to(device)\n",
    "\n",
    "\n",
    "#train start\n",
    "lr=20\n",
    "num_epoch=30\n",
    "best_loss=None\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(1,num_epoch+1):\n",
    "    train(model,train_data,lr)\n",
    "    val_loss = evaluate(model,val_data)\n",
    "    print('-' * 89)\n",
    "    print(f'| End of epoch {epoch:2d} | valid loss {val_loss:5.2f} | valid ppl {math.exp(val_loss):8.2f}')\n",
    "    print('-' * 89)\n",
    "    \n",
    "    if not best_loss or val_loss < best_loss:\n",
    "        torch.save(model,'model.pt')\n",
    "        best_loss = val_loss\n",
    "    else:\n",
    "        lr /=4.0\n",
    "\n",
    "print('Train done!!!!')\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "### END YOUR CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gpv4N8wl4w8p"
   },
   "source": [
    "### 5. 학습한 언어 모델로 문장 생성\n",
    "\n",
    "앞서 학습한 모델을 불러와서 문장을 생성해봅시다.\n",
    "기본 과제 2와 똑같이 generate.txt를 저장하면 됩니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "004fe85f1b9a4fd889add3e17c788137",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Eval'), FloatProgress(value=0.0, max=250.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================================================================================\n",
      "| End of training | test loss  5.13 | test ppl   168.97\n",
      "=========================================================================================\n"
     ]
    }
   ],
   "source": [
    "model =torch.load('model.pt', map_location=device)\n",
    "model.rnn.flatten_parameters()\n",
    "test_loss = evaluate(model, test_data)\n",
    "print('=' * 89)\n",
    "print(f'| End of training | test loss {test_loss:5.2f} | test ppl {math.exp(test_loss):8.2f}')\n",
    "print('=' * 89)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "id": "GQjeaKjO4JAh"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5da98c88946e467b8c1366d78efdfe71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Generation'), FloatProgress(value=0.0, max=1000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "### YOUR CODE HERE\n",
    "### 기본 과제 2를 참고해서 Langauge model로 문장을 생성하는 코드를 작성해 보세요.\n",
    "### ANSWER HERE ###\n",
    "from tqdm.notebook import trange\n",
    "\n",
    "num_words = 1000\n",
    "temperature = 1.0\n",
    "\n",
    "hidden = model.init_hidden(1)\n",
    "input = torch.randint(vocab_size, (1, 1), dtype=torch.long).to(device)\n",
    "outputs = []\n",
    "\n",
    "for i in trange(num_words, desc=\"Generation\"):\n",
    "    with torch.no_grad():\n",
    "        log_prob, hidden = model(input, hidden)\n",
    "\n",
    "    weights = (log_prob.squeeze() / temperature).exp()\n",
    "    token_id = torch.multinomial(weights, 1)\n",
    "    outputs.append(token_id.item())\n",
    "    input = token_id.unsqueeze(0)\n",
    "    \n",
    "outputs =tokenizer.decode(outputs)\n",
    "\n",
    "with open('generate.txt', 'w') as fd:\n",
    "    fd.write(' '.join(outputs).replace('<eos>', '\\n'))\n",
    "\n",
    "### END YOUR CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "[Basic 3] Subword-level Language Model.ipynb의 사본",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
